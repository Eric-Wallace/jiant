09/16 12:14:43 PM: Git branch: master
09/16 12:14:43 PM: Git SHA: 93c1dfd555f3458ddbb66d458dfeca984f2d8527
09/16 12:14:43 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-RANDOM-top/",
  "exp_name": "experiments/ner-ontonotes-RANDOM-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-RANDOM-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/RANDOM",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-RANDOM-top__run",
  "run_dir": "./experiments/ner-ontonotes-RANDOM-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:14:43 PM: Saved config to ./experiments/ner-ontonotes-RANDOM-top/run/params.conf
09/16 12:14:43 PM: Using random seed 1234
09/16 12:15:22 PM: Using GPU 0
09/16 12:15:22 PM: Loading tasks...
09/16 12:15:22 PM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-RANDOM-top/
09/16 12:15:22 PM: 	Creating task edges-ner-ontonotes from scratch.
09/16 12:15:23 PM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 12:15:25 PM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 12:15:25 PM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 12:15:25 PM: 	Building vocab from scratch.
09/16 12:15:25 PM: 	Counting units for task edges-ner-ontonotes.
09/16 12:15:27 PM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 12:15:28 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:28 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:15:28 PM: 	Saved vocab to ./experiments/ner-ontonotes-RANDOM-top/vocab
09/16 12:15:28 PM: Loading token dictionary from ./experiments/ner-ontonotes-RANDOM-top/vocab.
09/16 12:15:28 PM: 	Loaded vocab from ./experiments/ner-ontonotes-RANDOM-top/vocab
09/16 12:15:28 PM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 12:15:28 PM: 	Vocab namespace tokens: size 22840
09/16 12:15:28 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:15:28 PM: 	Vocab namespace chars: size 77
09/16 12:15:28 PM: 	Finished building vocab.
09/16 12:15:28 PM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 12:15:43 PM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-RANDOM-top/preproc/edges-ner-ontonotes__train_data
09/16 12:15:43 PM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-RANDOM-top/preproc/edges-ner-ontonotes__val_data
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 12:15:49 PM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-RANDOM-top/preproc/edges-ner-ontonotes__test_data
09/16 12:15:49 PM: 	Finished indexing tasks
09/16 12:15:49 PM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 12:15:49 PM: 	  Training on 
09/16 12:15:49 PM: 	  Evaluating on edges-ner-ontonotes
09/16 12:15:49 PM: 	Finished loading tasks in 27.370s
09/16 12:15:49 PM: 	 Tasks: ['edges-ner-ontonotes']
09/16 12:15:49 PM: Building model...
09/16 12:15:49 PM: Using BERT model (bert-base-uncased).
09/16 12:15:49 PM: LOADING A RANDOMLY WEIGHTS BERT
09/16 12:15:54 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpgtoe24qn
09/16 12:15:55 PM: copying /tmp/tmpgtoe24qn to cache at ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 12:15:55 PM: creating metadata file for ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 12:15:55 PM: removing temp file /tmp/tmpgtoe24qn
09/16 12:15:55 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 12:15:55 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:15:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpxw6lt1m9
09/16 12:28:33 PM: copying /tmp/tmpxw6lt1m9 to cache at ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 12:28:35 PM: creating metadata file for ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 12:28:35 PM: removing temp file /tmp/tmpxw6lt1m9
09/16 12:28:35 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 12:28:45 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpbx1n_384
09/16 12:28:47 PM: copying /tmp/tmpbx1n_384 to cache at ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:28:47 PM: creating metadata file for ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:28:47 PM: removing temp file /tmp/tmpbx1n_384
09/16 12:28:47 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-RANDOM-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:28:47 PM: Initializing parameters
09/16 12:28:47 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:28:47 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:28:47 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:28:47 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:28:47 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:28:47 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:28:47 PM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 12:29:29 PM: Model specification:
09/16 12:29:29 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 12:29:29 PM: Model parameters:
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:29:29 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:29:29 PM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:29:29 PM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:29:29 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 12:29:29 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 12:29:29 PM: Total number of parameters: 109688338 (1.09688e+08)
09/16 12:29:29 PM: Number of trainable parameters: 206098 (206098)
09/16 12:29:29 PM: Finished building model in 819.689s
09/16 12:29:29 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 12:29:39 PM: patience = 9
09/16 12:29:39 PM: val_interval = 1000
09/16 12:29:39 PM: max_vals = 250
09/16 12:29:39 PM: cuda_device = 0
09/16 12:29:39 PM: grad_norm = 5.0
09/16 12:29:39 PM: grad_clipping = None
09/16 12:29:39 PM: lr_decay = 0.99
09/16 12:29:39 PM: min_lr = 1e-06
09/16 12:29:39 PM: keep_all_checkpoints = 0
09/16 12:29:39 PM: val_data_limit = 5000
09/16 12:29:39 PM: max_epochs = -1
09/16 12:29:39 PM: dec_val_scale = 250
09/16 12:29:39 PM: training_data_fraction = 1
09/16 12:29:39 PM: type = adam
09/16 12:29:39 PM: parameter_groups = None
09/16 12:29:39 PM: Number of trainable parameters: 206098
09/16 12:29:39 PM: infer_type_and_cast = True
09/16 12:29:39 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:29:39 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:29:39 PM: lr = 0.0001
09/16 12:29:39 PM: amsgrad = True
09/16 12:29:41 PM: type = reduce_on_plateau
09/16 12:29:41 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:29:41 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:29:41 PM: mode = max
09/16 12:29:41 PM: factor = 0.5
09/16 12:29:41 PM: patience = 3
09/16 12:29:41 PM: threshold = 0.0001
09/16 12:29:41 PM: threshold_mode = abs
09/16 12:29:41 PM: verbose = True
09/16 12:29:41 PM: type = adam
09/16 12:29:41 PM: parameter_groups = None
09/16 12:29:41 PM: Number of trainable parameters: 206098
09/16 12:29:41 PM: infer_type_and_cast = True
09/16 12:29:41 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:29:41 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:29:41 PM: lr = 0.0001
09/16 12:29:41 PM: amsgrad = True
09/16 12:29:41 PM: type = reduce_on_plateau
09/16 12:29:41 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:29:41 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:29:41 PM: mode = max
09/16 12:29:41 PM: factor = 0.5
09/16 12:29:41 PM: patience = 3
09/16 12:29:41 PM: threshold = 0.0001
09/16 12:29:41 PM: threshold_mode = abs
09/16 12:29:41 PM: verbose = True
09/16 12:29:41 PM: Starting training without restoring from a checkpoint.
09/16 12:29:41 PM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 12:29:41 PM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 12:29:51 PM: Update 17: task edges-ner-ontonotes, batch 17 (17): mcc: 0.0260, acc: 0.0171, precision: 0.0697, recall: 0.1877, f1: 0.1017, edges-ner-ontonotes_loss: 0.4762
09/16 12:30:01 PM: Update 85: task edges-ner-ontonotes, batch 85 (85): mcc: 0.0119, acc: 0.0041, precision: 0.0697, recall: 0.0446, f1: 0.0544, edges-ner-ontonotes_loss: 0.2465
09/16 12:30:11 PM: Update 180: task edges-ner-ontonotes, batch 180 (180): mcc: 0.0093, acc: 0.0027, precision: 0.0718, recall: 0.0218, f1: 0.0334, edges-ner-ontonotes_loss: 0.2067
09/16 12:30:21 PM: Update 300: task edges-ner-ontonotes, batch 300 (300): mcc: 0.0166, acc: 0.0059, precision: 0.0926, recall: 0.0174, f1: 0.0293, edges-ner-ontonotes_loss: 0.1890
09/16 12:30:31 PM: Update 328: task edges-ner-ontonotes, batch 328 (328): mcc: 0.0186, acc: 0.0065, precision: 0.0994, recall: 0.0167, f1: 0.0286, edges-ner-ontonotes_loss: 0.1867
09/16 12:30:41 PM: Update 414: task edges-ner-ontonotes, batch 414 (414): mcc: 0.0404, acc: 0.0146, precision: 0.1605, recall: 0.0223, f1: 0.0392, edges-ner-ontonotes_loss: 0.1807
09/16 12:30:51 PM: Update 497: task edges-ner-ontonotes, batch 497 (497): mcc: 0.0767, acc: 0.0279, precision: 0.2608, recall: 0.0342, f1: 0.0604, edges-ner-ontonotes_loss: 0.1754
09/16 12:31:01 PM: Update 550: task edges-ner-ontonotes, batch 550 (550): mcc: 0.1004, acc: 0.0367, precision: 0.3252, recall: 0.0423, f1: 0.0748, edges-ner-ontonotes_loss: 0.1727
09/16 12:31:11 PM: Update 608: task edges-ner-ontonotes, batch 608 (608): mcc: 0.1271, acc: 0.0473, precision: 0.3927, recall: 0.0523, f1: 0.0924, edges-ner-ontonotes_loss: 0.1698
09/16 12:31:22 PM: Update 648: task edges-ner-ontonotes, batch 648 (648): mcc: 0.1390, acc: 0.0521, precision: 0.4231, recall: 0.0567, f1: 0.1000, edges-ner-ontonotes_loss: 0.1683
09/16 12:31:32 PM: Update 701: task edges-ner-ontonotes, batch 701 (701): mcc: 0.1519, acc: 0.0570, precision: 0.4564, recall: 0.0614, f1: 0.1083, edges-ner-ontonotes_loss: 0.1666
09/16 12:31:42 PM: Update 753: task edges-ner-ontonotes, batch 753 (753): mcc: 0.1701, acc: 0.0647, precision: 0.4982, recall: 0.0690, f1: 0.1211, edges-ner-ontonotes_loss: 0.1649
09/16 12:31:52 PM: Update 804: task edges-ner-ontonotes, batch 804 (804): mcc: 0.1883, acc: 0.0730, precision: 0.5359, recall: 0.0772, f1: 0.1349, edges-ner-ontonotes_loss: 0.1632
09/16 12:32:02 PM: Update 859: task edges-ner-ontonotes, batch 859 (859): mcc: 0.2046, acc: 0.0809, precision: 0.5675, recall: 0.0849, f1: 0.1478, edges-ner-ontonotes_loss: 0.1614
09/16 12:32:12 PM: Update 907: task edges-ner-ontonotes, batch 907 (907): mcc: 0.2207, acc: 0.0891, precision: 0.5955, recall: 0.0931, f1: 0.1611, edges-ner-ontonotes_loss: 0.1598
09/16 12:32:27 PM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.2301, acc: 0.0942, precision: 0.6106, recall: 0.0982, f1: 0.1692, edges-ner-ontonotes_loss: 0.1589
09/16 12:32:37 PM: Update 994: task edges-ner-ontonotes, batch 994 (994): mcc: 0.2448, acc: 0.1023, precision: 0.6334, recall: 0.1064, f1: 0.1821, edges-ner-ontonotes_loss: 0.1576
09/16 12:32:38 PM: ***** Step 1000 / Validation 1 *****
09/16 12:32:38 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:32:38 PM: Validating...
09/16 12:32:47 PM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.2961, acc: 0.1335, precision: 0.7168, recall: 0.1343, f1: 0.2262, edges-ner-ontonotes_loss: 0.1598
09/16 12:32:57 PM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.3679, acc: 0.1789, precision: 0.8102, recall: 0.1796, f1: 0.2940, edges-ner-ontonotes_loss: 0.1481
09/16 12:33:10 PM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.3895, acc: 0.1946, precision: 0.8308, recall: 0.1955, f1: 0.3165, edges-ner-ontonotes_loss: 0.1423
09/16 12:33:12 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:33:12 PM: Best result seen so far for micro.
09/16 12:33:12 PM: Best result seen so far for macro.
09/16 12:33:12 PM: Updating LR scheduler:
09/16 12:33:12 PM: 	Best result seen so far for macro_avg: 0.318
09/16 12:33:12 PM: 	# validation passes without improvement: 0
09/16 12:33:12 PM: edges-ner-ontonotes_loss: training: 0.157486 validation: 0.141464
09/16 12:33:12 PM: macro_avg: validation: 0.318332
09/16 12:33:12 PM: micro_avg: validation: 0.000000
09/16 12:33:12 PM: edges-ner-ontonotes_mcc: training: 0.246238 validation: 0.391070
09/16 12:33:12 PM: edges-ner-ontonotes_acc: training: 0.103167 validation: 0.195936
09/16 12:33:12 PM: edges-ner-ontonotes_precision: training: 0.635349 validation: 0.831518
09/16 12:33:12 PM: edges-ner-ontonotes_recall: training: 0.107217 validation: 0.196846
09/16 12:33:12 PM: edges-ner-ontonotes_f1: training: 0.183472 validation: 0.318332
09/16 12:33:12 PM: Global learning rate: 0.0001
09/16 12:33:12 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:33:20 PM: Update 1031: task edges-ner-ontonotes, batch 31 (1031): mcc: 0.4292, acc: 0.2265, precision: 0.8465, recall: 0.2318, f1: 0.3639, edges-ner-ontonotes_loss: 0.1334
09/16 12:33:30 PM: Update 1089: task edges-ner-ontonotes, batch 89 (1089): mcc: 0.4419, acc: 0.2419, precision: 0.8439, recall: 0.2464, f1: 0.3814, edges-ner-ontonotes_loss: 0.1311
09/16 12:33:40 PM: Update 1147: task edges-ner-ontonotes, batch 147 (1147): mcc: 0.4461, acc: 0.2459, precision: 0.8438, recall: 0.2511, f1: 0.3870, edges-ner-ontonotes_loss: 0.1301
09/16 12:33:50 PM: Update 1205: task edges-ner-ontonotes, batch 205 (1205): mcc: 0.4511, acc: 0.2516, precision: 0.8439, recall: 0.2565, f1: 0.3935, edges-ner-ontonotes_loss: 0.1290
09/16 12:34:05 PM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.4509, acc: 0.2537, precision: 0.8368, recall: 0.2587, f1: 0.3952, edges-ner-ontonotes_loss: 0.1289
09/16 12:34:15 PM: Update 1318: task edges-ner-ontonotes, batch 318 (1318): mcc: 0.4379, acc: 0.2431, precision: 0.8269, recall: 0.2476, f1: 0.3810, edges-ner-ontonotes_loss: 0.1329
09/16 12:34:25 PM: Update 1381: task edges-ner-ontonotes, batch 381 (1381): mcc: 0.4302, acc: 0.2364, precision: 0.8219, recall: 0.2406, f1: 0.3723, edges-ner-ontonotes_loss: 0.1347
09/16 12:34:35 PM: Update 1452: task edges-ner-ontonotes, batch 452 (1452): mcc: 0.4291, acc: 0.2353, precision: 0.8221, recall: 0.2394, f1: 0.3708, edges-ner-ontonotes_loss: 0.1353
09/16 12:34:45 PM: Update 1517: task edges-ner-ontonotes, batch 517 (1517): mcc: 0.4293, acc: 0.2361, precision: 0.8210, recall: 0.2400, f1: 0.3714, edges-ner-ontonotes_loss: 0.1359
09/16 12:34:56 PM: Update 1562: task edges-ner-ontonotes, batch 562 (1562): mcc: 0.4300, acc: 0.2371, precision: 0.8204, recall: 0.2409, f1: 0.3725, edges-ner-ontonotes_loss: 0.1360
09/16 12:35:06 PM: Update 1627: task edges-ner-ontonotes, batch 627 (1627): mcc: 0.4282, acc: 0.2362, precision: 0.8175, recall: 0.2399, f1: 0.3709, edges-ner-ontonotes_loss: 0.1361
09/16 12:35:16 PM: Update 1692: task edges-ner-ontonotes, batch 692 (1692): mcc: 0.4275, acc: 0.2356, precision: 0.8171, recall: 0.2392, f1: 0.3700, edges-ner-ontonotes_loss: 0.1360
09/16 12:35:26 PM: Update 1759: task edges-ner-ontonotes, batch 759 (1759): mcc: 0.4278, acc: 0.2364, precision: 0.8167, recall: 0.2397, f1: 0.3707, edges-ner-ontonotes_loss: 0.1358
09/16 12:35:36 PM: Update 1844: task edges-ner-ontonotes, batch 844 (1844): mcc: 0.4308, acc: 0.2392, precision: 0.8182, recall: 0.2426, f1: 0.3742, edges-ner-ontonotes_loss: 0.1351
09/16 12:35:46 PM: Update 1895: task edges-ner-ontonotes, batch 895 (1895): mcc: 0.4314, acc: 0.2407, precision: 0.8157, recall: 0.2440, f1: 0.3757, edges-ner-ontonotes_loss: 0.1348
09/16 12:35:56 PM: Update 1986: task edges-ner-ontonotes, batch 986 (1986): mcc: 0.4340, acc: 0.2445, precision: 0.8126, recall: 0.2480, f1: 0.3800, edges-ner-ontonotes_loss: 0.1341
09/16 12:35:58 PM: ***** Step 2000 / Validation 2 *****
09/16 12:36:00 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:36:00 PM: Validating...
09/16 12:36:06 PM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.4359, acc: 0.2238, precision: 0.8972, recall: 0.2241, f1: 0.3586, edges-ner-ontonotes_loss: 0.1315
09/16 12:36:17 PM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.4642, acc: 0.2488, precision: 0.9125, recall: 0.2490, f1: 0.3913, edges-ner-ontonotes_loss: 0.1281
09/16 12:36:26 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:36:26 PM: Best result seen so far for macro.
09/16 12:36:26 PM: Updating LR scheduler:
09/16 12:36:26 PM: 	Best result seen so far for macro_avg: 0.386
09/16 12:36:26 PM: 	# validation passes without improvement: 0
09/16 12:36:26 PM: edges-ner-ontonotes_loss: training: 0.134028 validation: 0.127000
09/16 12:36:26 PM: macro_avg: validation: 0.385608
09/16 12:36:26 PM: micro_avg: validation: 0.000000
09/16 12:36:26 PM: edges-ner-ontonotes_mcc: training: 0.434630 validation: 0.459364
09/16 12:36:26 PM: edges-ner-ontonotes_acc: training: 0.245203 validation: 0.244465
09/16 12:36:26 PM: edges-ner-ontonotes_precision: training: 0.812387 validation: 0.910271
09/16 12:36:26 PM: edges-ner-ontonotes_recall: training: 0.248731 validation: 0.244616
09/16 12:36:26 PM: edges-ner-ontonotes_f1: training: 0.380854 validation: 0.385608
09/16 12:36:26 PM: Global learning rate: 0.0001
09/16 12:36:26 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:36:27 PM: Update 2007: task edges-ner-ontonotes, batch 7 (2007): mcc: 0.4357, acc: 0.2476, precision: 0.8010, recall: 0.2539, f1: 0.3856, edges-ner-ontonotes_loss: 0.1287
09/16 12:36:37 PM: Update 2073: task edges-ner-ontonotes, batch 73 (2073): mcc: 0.4756, acc: 0.2918, precision: 0.8165, recall: 0.2952, f1: 0.4336, edges-ner-ontonotes_loss: 0.1250
09/16 12:36:47 PM: Update 2145: task edges-ner-ontonotes, batch 145 (2145): mcc: 0.4844, acc: 0.3028, precision: 0.8152, recall: 0.3065, f1: 0.4455, edges-ner-ontonotes_loss: 0.1238
09/16 12:36:57 PM: Update 2185: task edges-ner-ontonotes, batch 185 (2185): mcc: 0.4808, acc: 0.3027, precision: 0.8036, recall: 0.3069, f1: 0.4442, edges-ner-ontonotes_loss: 0.1241
09/16 12:37:07 PM: Update 2261: task edges-ner-ontonotes, batch 261 (2261): mcc: 0.4778, acc: 0.2979, precision: 0.8000, recall: 0.3047, f1: 0.4413, edges-ner-ontonotes_loss: 0.1246
09/16 12:37:18 PM: Update 2325: task edges-ner-ontonotes, batch 325 (2325): mcc: 0.4791, acc: 0.2992, precision: 0.7992, recall: 0.3066, f1: 0.4432, edges-ner-ontonotes_loss: 0.1244
09/16 12:37:28 PM: Update 2391: task edges-ner-ontonotes, batch 391 (2391): mcc: 0.4788, acc: 0.2982, precision: 0.7981, recall: 0.3066, f1: 0.4431, edges-ner-ontonotes_loss: 0.1240
09/16 12:37:38 PM: Update 2451: task edges-ner-ontonotes, batch 451 (2451): mcc: 0.4823, acc: 0.3019, precision: 0.7984, recall: 0.3110, f1: 0.4477, edges-ner-ontonotes_loss: 0.1233
09/16 12:37:51 PM: Update 2496: task edges-ner-ontonotes, batch 496 (2496): mcc: 0.4832, acc: 0.3028, precision: 0.7970, recall: 0.3127, f1: 0.4492, edges-ner-ontonotes_loss: 0.1230
09/16 12:38:01 PM: Update 2566: task edges-ner-ontonotes, batch 566 (2566): mcc: 0.4836, acc: 0.3034, precision: 0.7960, recall: 0.3137, f1: 0.4500, edges-ner-ontonotes_loss: 0.1231
09/16 12:38:11 PM: Update 2639: task edges-ner-ontonotes, batch 639 (2639): mcc: 0.4856, acc: 0.3059, precision: 0.7950, recall: 0.3167, f1: 0.4529, edges-ner-ontonotes_loss: 0.1229
09/16 12:38:21 PM: Update 2707: task edges-ner-ontonotes, batch 707 (2707): mcc: 0.4872, acc: 0.3078, precision: 0.7945, recall: 0.3189, f1: 0.4551, edges-ner-ontonotes_loss: 0.1227
09/16 12:38:34 PM: Update 2766: task edges-ner-ontonotes, batch 766 (2766): mcc: 0.4885, acc: 0.3095, precision: 0.7943, recall: 0.3207, f1: 0.4569, edges-ner-ontonotes_loss: 0.1223
09/16 12:38:47 PM: Update 2809: task edges-ner-ontonotes, batch 809 (2809): mcc: 0.4893, acc: 0.3111, precision: 0.7921, recall: 0.3226, f1: 0.4585, edges-ner-ontonotes_loss: 0.1221
09/16 12:38:58 PM: Update 2873: task edges-ner-ontonotes, batch 873 (2873): mcc: 0.4854, acc: 0.3075, precision: 0.7896, recall: 0.3188, f1: 0.4542, edges-ner-ontonotes_loss: 0.1233
09/16 12:39:09 PM: Update 2936: task edges-ner-ontonotes, batch 936 (2936): mcc: 0.4834, acc: 0.3059, precision: 0.7884, recall: 0.3168, f1: 0.4520, edges-ner-ontonotes_loss: 0.1239
09/16 12:39:17 PM: ***** Step 3000 / Validation 3 *****
09/16 12:39:17 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:39:19 PM: Validating...
09/16 12:39:19 PM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.5661, acc: 0.3934, precision: 0.8571, recall: 0.3934, f1: 0.5393, edges-ner-ontonotes_loss: 0.1497
09/16 12:39:29 PM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.4343, acc: 0.2325, precision: 0.8608, recall: 0.2330, f1: 0.3667, edges-ner-ontonotes_loss: 0.1284
09/16 12:39:40 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.4715, acc: 0.2679, precision: 0.8683, recall: 0.2712, f1: 0.4133, edges-ner-ontonotes_loss: 0.1243
09/16 12:39:47 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:39:47 PM: Best result seen so far for macro.
09/16 12:39:47 PM: Updating LR scheduler:
09/16 12:39:47 PM: 	Best result seen so far for macro_avg: 0.416
09/16 12:39:47 PM: 	# validation passes without improvement: 0
09/16 12:39:47 PM: edges-ner-ontonotes_loss: training: 0.124503 validation: 0.122508
09/16 12:39:47 PM: macro_avg: validation: 0.416186
09/16 12:39:47 PM: micro_avg: validation: 0.000000
09/16 12:39:47 PM: edges-ner-ontonotes_mcc: training: 0.483035 validation: 0.473575
09/16 12:39:47 PM: edges-ner-ontonotes_acc: training: 0.305791 validation: 0.270322
09/16 12:39:47 PM: edges-ner-ontonotes_precision: training: 0.788096 validation: 0.867788
09/16 12:39:47 PM: edges-ner-ontonotes_recall: training: 0.316412 validation: 0.273734
09/16 12:39:47 PM: edges-ner-ontonotes_f1: training: 0.451537 validation: 0.416186
09/16 12:39:47 PM: Global learning rate: 0.0001
09/16 12:39:47 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:39:50 PM: Update 3014: task edges-ner-ontonotes, batch 14 (3014): mcc: 0.4629, acc: 0.2794, precision: 0.7976, recall: 0.2873, f1: 0.4225, edges-ner-ontonotes_loss: 0.1348
09/16 12:40:00 PM: Update 3081: task edges-ner-ontonotes, batch 81 (3081): mcc: 0.4742, acc: 0.2957, precision: 0.7967, recall: 0.3016, f1: 0.4375, edges-ner-ontonotes_loss: 0.1310
09/16 12:40:10 PM: Update 3138: task edges-ner-ontonotes, batch 138 (3138): mcc: 0.4659, acc: 0.2894, precision: 0.7881, recall: 0.2948, f1: 0.4291, edges-ner-ontonotes_loss: 0.1305
09/16 12:40:20 PM: Update 3202: task edges-ner-ontonotes, batch 202 (3202): mcc: 0.4644, acc: 0.2896, precision: 0.7822, recall: 0.2954, f1: 0.4289, edges-ner-ontonotes_loss: 0.1294
09/16 12:40:30 PM: Update 3267: task edges-ner-ontonotes, batch 267 (3267): mcc: 0.4679, acc: 0.2929, precision: 0.7849, recall: 0.2987, f1: 0.4327, edges-ner-ontonotes_loss: 0.1279
09/16 12:40:41 PM: Update 3357: task edges-ner-ontonotes, batch 357 (3357): mcc: 0.4696, acc: 0.2946, precision: 0.7861, recall: 0.3003, f1: 0.4346, edges-ner-ontonotes_loss: 0.1270
09/16 12:40:51 PM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.4710, acc: 0.2967, precision: 0.7851, recall: 0.3025, f1: 0.4367, edges-ner-ontonotes_loss: 0.1267
09/16 12:41:01 PM: Update 3509: task edges-ner-ontonotes, batch 509 (3509): mcc: 0.4724, acc: 0.2992, precision: 0.7822, recall: 0.3054, f1: 0.4393, edges-ner-ontonotes_loss: 0.1266
09/16 12:41:13 PM: Update 3606: task edges-ner-ontonotes, batch 606 (3606): mcc: 0.4758, acc: 0.3035, precision: 0.7813, recall: 0.3101, f1: 0.4440, edges-ner-ontonotes_loss: 0.1256
09/16 12:41:26 PM: Update 3668: task edges-ner-ontonotes, batch 668 (3668): mcc: 0.4786, acc: 0.3068, precision: 0.7813, recall: 0.3137, f1: 0.4477, edges-ner-ontonotes_loss: 0.1250
09/16 12:41:41 PM: Update 3739: task edges-ner-ontonotes, batch 739 (3739): mcc: 0.4827, acc: 0.3111, precision: 0.7832, recall: 0.3181, f1: 0.4525, edges-ner-ontonotes_loss: 0.1245
09/16 12:41:51 PM: Update 3804: task edges-ner-ontonotes, batch 804 (3804): mcc: 0.4834, acc: 0.3123, precision: 0.7803, recall: 0.3204, f1: 0.4542, edges-ner-ontonotes_loss: 0.1242
09/16 12:42:01 PM: Update 3873: task edges-ner-ontonotes, batch 873 (3873): mcc: 0.4844, acc: 0.3134, precision: 0.7790, recall: 0.3222, f1: 0.4559, edges-ner-ontonotes_loss: 0.1238
09/16 12:42:11 PM: Update 3941: task edges-ner-ontonotes, batch 941 (3941): mcc: 0.4865, acc: 0.3151, precision: 0.7796, recall: 0.3247, f1: 0.4584, edges-ner-ontonotes_loss: 0.1234
09/16 12:42:19 PM: ***** Step 4000 / Validation 4 *****
09/16 12:42:19 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:42:19 PM: Validating...
09/16 12:42:21 PM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.3896, acc: 0.2360, precision: 0.6986, recall: 0.2376, f1: 0.3546, edges-ner-ontonotes_loss: 0.1541
09/16 12:42:31 PM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.4458, acc: 0.2650, precision: 0.7894, recall: 0.2700, f1: 0.4023, edges-ner-ontonotes_loss: 0.1312
09/16 12:42:41 PM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.5010, acc: 0.3091, precision: 0.8363, recall: 0.3184, f1: 0.4612, edges-ner-ontonotes_loss: 0.1212
09/16 12:42:45 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:42:46 PM: Best result seen so far for macro.
09/16 12:42:46 PM: Updating LR scheduler:
09/16 12:42:46 PM: 	Best result seen so far for macro_avg: 0.469
09/16 12:42:46 PM: 	# validation passes without improvement: 0
09/16 12:42:46 PM: edges-ner-ontonotes_loss: training: 0.122966 validation: 0.119202
09/16 12:42:46 PM: macro_avg: validation: 0.468921
09/16 12:42:46 PM: micro_avg: validation: 0.000000
09/16 12:42:46 PM: edges-ner-ontonotes_mcc: training: 0.488385 validation: 0.508238
09/16 12:42:46 PM: edges-ner-ontonotes_acc: training: 0.316992 validation: 0.316045
09/16 12:42:46 PM: edges-ner-ontonotes_precision: training: 0.780084 validation: 0.842178
09/16 12:42:46 PM: edges-ner-ontonotes_recall: training: 0.326963 validation: 0.324917
09/16 12:42:46 PM: edges-ner-ontonotes_f1: training: 0.460791 validation: 0.468921
09/16 12:42:46 PM: Global learning rate: 0.0001
09/16 12:42:46 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:42:51 PM: Update 4031: task edges-ner-ontonotes, batch 31 (4031): mcc: 0.5121, acc: 0.3420, precision: 0.7816, recall: 0.3579, f1: 0.4910, edges-ner-ontonotes_loss: 0.1184
09/16 12:43:01 PM: Update 4065: task edges-ner-ontonotes, batch 65 (4065): mcc: 0.5147, acc: 0.3451, precision: 0.7835, recall: 0.3604, f1: 0.4937, edges-ner-ontonotes_loss: 0.1180
09/16 12:43:11 PM: Update 4125: task edges-ner-ontonotes, batch 125 (4125): mcc: 0.5118, acc: 0.3415, precision: 0.7780, recall: 0.3592, f1: 0.4915, edges-ner-ontonotes_loss: 0.1178
09/16 12:43:24 PM: Update 4193: task edges-ner-ontonotes, batch 193 (4193): mcc: 0.5168, acc: 0.3466, precision: 0.7829, recall: 0.3637, f1: 0.4967, edges-ner-ontonotes_loss: 0.1165
09/16 12:43:34 PM: Update 4255: task edges-ner-ontonotes, batch 255 (4255): mcc: 0.5175, acc: 0.3475, precision: 0.7837, recall: 0.3642, f1: 0.4973, edges-ner-ontonotes_loss: 0.1168
09/16 12:43:44 PM: Update 4323: task edges-ner-ontonotes, batch 323 (4323): mcc: 0.5150, acc: 0.3458, precision: 0.7795, recall: 0.3629, f1: 0.4952, edges-ner-ontonotes_loss: 0.1170
09/16 12:43:55 PM: Update 4366: task edges-ner-ontonotes, batch 366 (4366): mcc: 0.5127, acc: 0.3450, precision: 0.7753, recall: 0.3619, f1: 0.4935, edges-ner-ontonotes_loss: 0.1175
09/16 12:44:05 PM: Update 4447: task edges-ner-ontonotes, batch 447 (4447): mcc: 0.5056, acc: 0.3376, precision: 0.7733, recall: 0.3532, f1: 0.4849, edges-ner-ontonotes_loss: 0.1203
09/16 12:44:15 PM: Update 4507: task edges-ner-ontonotes, batch 507 (4507): mcc: 0.5012, acc: 0.3331, precision: 0.7716, recall: 0.3481, f1: 0.4797, edges-ner-ontonotes_loss: 0.1217
09/16 12:44:26 PM: Update 4580: task edges-ner-ontonotes, batch 580 (4580): mcc: 0.4992, acc: 0.3319, precision: 0.7695, recall: 0.3464, f1: 0.4778, edges-ner-ontonotes_loss: 0.1227
09/16 12:44:36 PM: Update 4642: task edges-ner-ontonotes, batch 642 (4642): mcc: 0.4985, acc: 0.3311, precision: 0.7700, recall: 0.3452, f1: 0.4767, edges-ner-ontonotes_loss: 0.1233
09/16 12:44:47 PM: Update 4679: task edges-ner-ontonotes, batch 679 (4679): mcc: 0.4974, acc: 0.3302, precision: 0.7695, recall: 0.3440, f1: 0.4754, edges-ner-ontonotes_loss: 0.1235
09/16 12:44:58 PM: Update 4745: task edges-ner-ontonotes, batch 745 (4745): mcc: 0.4956, acc: 0.3286, precision: 0.7686, recall: 0.3420, f1: 0.4734, edges-ner-ontonotes_loss: 0.1234
09/16 12:45:08 PM: Update 4820: task edges-ner-ontonotes, batch 820 (4820): mcc: 0.4946, acc: 0.3274, precision: 0.7692, recall: 0.3404, f1: 0.4720, edges-ner-ontonotes_loss: 0.1234
09/16 12:45:18 PM: Update 4892: task edges-ner-ontonotes, batch 892 (4892): mcc: 0.4945, acc: 0.3270, precision: 0.7706, recall: 0.3395, f1: 0.4714, edges-ner-ontonotes_loss: 0.1233
09/16 12:45:29 PM: Update 4969: task edges-ner-ontonotes, batch 969 (4969): mcc: 0.4962, acc: 0.3285, precision: 0.7732, recall: 0.3406, f1: 0.4729, edges-ner-ontonotes_loss: 0.1230
09/16 12:45:38 PM: ***** Step 5000 / Validation 5 *****
09/16 12:45:38 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:45:38 PM: Validating...
09/16 12:45:39 PM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.4860, acc: 0.3463, precision: 0.7342, recall: 0.3463, f1: 0.4706, edges-ner-ontonotes_loss: 0.1511
09/16 12:45:49 PM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.5274, acc: 0.3356, precision: 0.8734, recall: 0.3358, f1: 0.4851, edges-ner-ontonotes_loss: 0.1167
09/16 12:45:59 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.5253, acc: 0.3353, precision: 0.8633, recall: 0.3374, f1: 0.4852, edges-ner-ontonotes_loss: 0.1157
09/16 12:46:05 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:46:05 PM: Best result seen so far for macro.
09/16 12:46:05 PM: Updating LR scheduler:
09/16 12:46:05 PM: 	Best result seen so far for macro_avg: 0.479
09/16 12:46:05 PM: 	# validation passes without improvement: 0
09/16 12:46:05 PM: edges-ner-ontonotes_loss: training: 0.123021 validation: 0.115116
09/16 12:46:05 PM: macro_avg: validation: 0.478921
09/16 12:46:05 PM: micro_avg: validation: 0.000000
09/16 12:46:05 PM: edges-ner-ontonotes_mcc: training: 0.495100 validation: 0.520780
09/16 12:46:05 PM: edges-ner-ontonotes_acc: training: 0.327509 validation: 0.329239
09/16 12:46:05 PM: edges-ner-ontonotes_precision: training: 0.772439 validation: 0.864437
09/16 12:46:05 PM: edges-ner-ontonotes_recall: training: 0.339464 validation: 0.331210
09/16 12:46:05 PM: edges-ner-ontonotes_f1: training: 0.471652 validation: 0.478921
09/16 12:46:05 PM: Global learning rate: 0.0001
09/16 12:46:05 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:46:09 PM: Update 5037: task edges-ner-ontonotes, batch 37 (5037): mcc: 0.4855, acc: 0.3237, precision: 0.7593, recall: 0.3329, f1: 0.4629, edges-ner-ontonotes_loss: 0.1236
09/16 12:46:19 PM: Update 5131: task edges-ner-ontonotes, batch 131 (5131): mcc: 0.4891, acc: 0.3254, precision: 0.7611, recall: 0.3370, f1: 0.4671, edges-ner-ontonotes_loss: 0.1223
09/16 12:46:30 PM: Update 5216: task edges-ner-ontonotes, batch 216 (5216): mcc: 0.4988, acc: 0.3358, precision: 0.7664, recall: 0.3473, f1: 0.4780, edges-ner-ontonotes_loss: 0.1209
09/16 12:46:44 PM: Update 5295: task edges-ner-ontonotes, batch 295 (5295): mcc: 0.5045, acc: 0.3414, precision: 0.7708, recall: 0.3530, f1: 0.4843, edges-ner-ontonotes_loss: 0.1193
09/16 12:46:54 PM: Update 5360: task edges-ner-ontonotes, batch 360 (5360): mcc: 0.5023, acc: 0.3387, precision: 0.7659, recall: 0.3524, f1: 0.4827, edges-ner-ontonotes_loss: 0.1194
09/16 12:47:05 PM: Update 5428: task edges-ner-ontonotes, batch 428 (5428): mcc: 0.5016, acc: 0.3373, precision: 0.7653, recall: 0.3517, f1: 0.4819, edges-ner-ontonotes_loss: 0.1195
09/16 12:47:15 PM: Update 5485: task edges-ner-ontonotes, batch 485 (5485): mcc: 0.5045, acc: 0.3396, precision: 0.7676, recall: 0.3546, f1: 0.4851, edges-ner-ontonotes_loss: 0.1190
09/16 12:47:25 PM: Update 5553: task edges-ner-ontonotes, batch 553 (5553): mcc: 0.5078, acc: 0.3423, precision: 0.7703, recall: 0.3578, f1: 0.4886, edges-ner-ontonotes_loss: 0.1184
09/16 12:47:36 PM: Update 5608: task edges-ner-ontonotes, batch 608 (5608): mcc: 0.5099, acc: 0.3443, precision: 0.7718, recall: 0.3599, f1: 0.4909, edges-ner-ontonotes_loss: 0.1181
09/16 12:47:46 PM: Update 5682: task edges-ner-ontonotes, batch 682 (5682): mcc: 0.5118, acc: 0.3465, precision: 0.7722, recall: 0.3623, f1: 0.4932, edges-ner-ontonotes_loss: 0.1177
09/16 12:47:56 PM: Update 5747: task edges-ner-ontonotes, batch 747 (5747): mcc: 0.5128, acc: 0.3471, precision: 0.7728, recall: 0.3633, f1: 0.4942, edges-ner-ontonotes_loss: 0.1175
09/16 12:48:06 PM: Update 5824: task edges-ner-ontonotes, batch 824 (5824): mcc: 0.5137, acc: 0.3481, precision: 0.7732, recall: 0.3643, f1: 0.4953, edges-ner-ontonotes_loss: 0.1173
09/16 12:48:17 PM: Update 5885: task edges-ner-ontonotes, batch 885 (5885): mcc: 0.5142, acc: 0.3486, precision: 0.7733, recall: 0.3650, f1: 0.4959, edges-ner-ontonotes_loss: 0.1173
09/16 12:48:31 PM: Update 5921: task edges-ner-ontonotes, batch 921 (5921): mcc: 0.5144, acc: 0.3487, precision: 0.7733, recall: 0.3653, f1: 0.4962, edges-ner-ontonotes_loss: 0.1173
09/16 12:48:41 PM: Update 5986: task edges-ner-ontonotes, batch 986 (5986): mcc: 0.5109, acc: 0.3453, precision: 0.7711, recall: 0.3616, f1: 0.4923, edges-ner-ontonotes_loss: 0.1184
09/16 12:48:45 PM: ***** Step 6000 / Validation 6 *****
09/16 12:48:45 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:48:45 PM: Validating...
09/16 12:48:53 PM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.4729, acc: 0.2642, precision: 0.8914, recall: 0.2651, f1: 0.4086, edges-ner-ontonotes_loss: 0.1221
09/16 12:49:03 PM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.5046, acc: 0.2941, precision: 0.9049, recall: 0.2962, f1: 0.4463, edges-ner-ontonotes_loss: 0.1174
09/16 12:49:14 PM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.5171, acc: 0.3067, precision: 0.9052, recall: 0.3106, f1: 0.4625, edges-ner-ontonotes_loss: 0.1139
09/16 12:49:16 PM: Updating LR scheduler:
09/16 12:49:16 PM: 	Best result seen so far for macro_avg: 0.479
09/16 12:49:16 PM: 	# validation passes without improvement: 1
09/16 12:49:16 PM: edges-ner-ontonotes_loss: training: 0.118660 validation: 0.113661
09/16 12:49:16 PM: macro_avg: validation: 0.462659
09/16 12:49:16 PM: micro_avg: validation: 0.000000
09/16 12:49:16 PM: edges-ner-ontonotes_mcc: training: 0.510350 validation: 0.517206
09/16 12:49:16 PM: edges-ner-ontonotes_acc: training: 0.344716 validation: 0.306870
09/16 12:49:16 PM: edges-ner-ontonotes_precision: training: 0.770992 validation: 0.905235
09/16 12:49:16 PM: edges-ner-ontonotes_recall: training: 0.360893 validation: 0.310737
09/16 12:49:16 PM: edges-ner-ontonotes_f1: training: 0.491650 validation: 0.462659
09/16 12:49:16 PM: Global learning rate: 0.0001
09/16 12:49:16 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:49:26 PM: Update 6063: task edges-ner-ontonotes, batch 63 (6063): mcc: 0.4759, acc: 0.3117, precision: 0.7634, recall: 0.3184, f1: 0.4493, edges-ner-ontonotes_loss: 0.1290
09/16 12:49:36 PM: Update 6121: task edges-ner-ontonotes, batch 121 (6121): mcc: 0.4736, acc: 0.3105, precision: 0.7584, recall: 0.3176, f1: 0.4477, edges-ner-ontonotes_loss: 0.1290
09/16 12:49:46 PM: Update 6207: task edges-ner-ontonotes, batch 207 (6207): mcc: 0.4795, acc: 0.3153, precision: 0.7623, recall: 0.3236, f1: 0.4543, edges-ner-ontonotes_loss: 0.1283
09/16 12:49:56 PM: Update 6241: task edges-ner-ontonotes, batch 241 (6241): mcc: 0.4791, acc: 0.3153, precision: 0.7606, recall: 0.3239, f1: 0.4543, edges-ner-ontonotes_loss: 0.1279
09/16 12:50:06 PM: Update 6325: task edges-ner-ontonotes, batch 325 (6325): mcc: 0.4828, acc: 0.3181, precision: 0.7643, recall: 0.3270, f1: 0.4581, edges-ner-ontonotes_loss: 0.1261
09/16 12:50:16 PM: Update 6422: task edges-ner-ontonotes, batch 422 (6422): mcc: 0.4864, acc: 0.3208, precision: 0.7691, recall: 0.3295, f1: 0.4614, edges-ner-ontonotes_loss: 0.1249
09/16 12:50:29 PM: Update 6487: task edges-ner-ontonotes, batch 487 (6487): mcc: 0.4886, acc: 0.3231, precision: 0.7702, recall: 0.3319, f1: 0.4639, edges-ner-ontonotes_loss: 0.1242
09/16 12:50:44 PM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.4923, acc: 0.3264, precision: 0.7733, recall: 0.3353, f1: 0.4678, edges-ner-ontonotes_loss: 0.1233
09/16 12:50:54 PM: Update 6606: task edges-ner-ontonotes, batch 606 (6606): mcc: 0.4928, acc: 0.3275, precision: 0.7719, recall: 0.3367, f1: 0.4689, edges-ner-ontonotes_loss: 0.1232
09/16 12:51:04 PM: Update 6702: task edges-ner-ontonotes, batch 702 (6702): mcc: 0.4947, acc: 0.3301, precision: 0.7712, recall: 0.3396, f1: 0.4715, edges-ner-ontonotes_loss: 0.1226
09/16 12:51:14 PM: Update 6791: task edges-ner-ontonotes, batch 791 (6791): mcc: 0.4974, acc: 0.3329, precision: 0.7722, recall: 0.3427, f1: 0.4747, edges-ner-ontonotes_loss: 0.1218
09/16 12:51:25 PM: Update 6851: task edges-ner-ontonotes, batch 851 (6851): mcc: 0.4990, acc: 0.3346, precision: 0.7728, recall: 0.3445, f1: 0.4766, edges-ner-ontonotes_loss: 0.1214
09/16 12:51:35 PM: Update 6916: task edges-ner-ontonotes, batch 916 (6916): mcc: 0.4987, acc: 0.3343, precision: 0.7710, recall: 0.3450, f1: 0.4767, edges-ner-ontonotes_loss: 0.1214
09/16 12:51:45 PM: Update 6984: task edges-ner-ontonotes, batch 984 (6984): mcc: 0.4995, acc: 0.3351, precision: 0.7696, recall: 0.3467, f1: 0.4781, edges-ner-ontonotes_loss: 0.1210
09/16 12:51:48 PM: ***** Step 7000 / Validation 7 *****
09/16 12:51:49 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:51:49 PM: Validating...
09/16 12:51:55 PM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.4702, acc: 0.2905, precision: 0.8028, recall: 0.2942, f1: 0.4306, edges-ner-ontonotes_loss: 0.1284
09/16 12:52:06 PM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.5112, acc: 0.3199, precision: 0.8464, recall: 0.3269, f1: 0.4717, edges-ner-ontonotes_loss: 0.1214
09/16 12:52:16 PM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.5314, acc: 0.3376, precision: 0.8596, recall: 0.3467, f1: 0.4941, edges-ner-ontonotes_loss: 0.1156
09/16 12:52:18 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:52:18 PM: Best result seen so far for macro.
09/16 12:52:18 PM: Updating LR scheduler:
09/16 12:52:18 PM: 	Best result seen so far for macro_avg: 0.495
09/16 12:52:18 PM: 	# validation passes without improvement: 0
09/16 12:52:18 PM: edges-ner-ontonotes_loss: training: 0.120885 validation: 0.115084
09/16 12:52:18 PM: macro_avg: validation: 0.494840
09/16 12:52:18 PM: micro_avg: validation: 0.000000
09/16 12:52:18 PM: edges-ner-ontonotes_mcc: training: 0.499713 validation: 0.532264
09/16 12:52:18 PM: edges-ner-ontonotes_acc: training: 0.335209 validation: 0.338110
09/16 12:52:18 PM: edges-ner-ontonotes_precision: training: 0.769660 validation: 0.860876
09/16 12:52:18 PM: edges-ner-ontonotes_recall: training: 0.347037 validation: 0.347210
09/16 12:52:18 PM: edges-ner-ontonotes_f1: training: 0.478376 validation: 0.494840
09/16 12:52:18 PM: Global learning rate: 0.0001
09/16 12:52:18 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:52:26 PM: Update 7060: task edges-ner-ontonotes, batch 60 (7060): mcc: 0.5191, acc: 0.3527, precision: 0.7667, recall: 0.3753, f1: 0.5039, edges-ner-ontonotes_loss: 0.1148
09/16 12:52:36 PM: Update 7126: task edges-ner-ontonotes, batch 126 (7126): mcc: 0.5172, acc: 0.3522, precision: 0.7636, recall: 0.3744, f1: 0.5024, edges-ner-ontonotes_loss: 0.1151
09/16 12:52:49 PM: Update 7164: task edges-ner-ontonotes, batch 164 (7164): mcc: 0.5231, acc: 0.3585, precision: 0.7675, recall: 0.3805, f1: 0.5088, edges-ner-ontonotes_loss: 0.1145
09/16 12:53:01 PM: Update 7232: task edges-ner-ontonotes, batch 232 (7232): mcc: 0.5214, acc: 0.3580, precision: 0.7649, recall: 0.3795, f1: 0.5073, edges-ner-ontonotes_loss: 0.1148
09/16 12:53:11 PM: Update 7297: task edges-ner-ontonotes, batch 297 (7297): mcc: 0.5248, acc: 0.3607, precision: 0.7709, recall: 0.3811, f1: 0.5101, edges-ner-ontonotes_loss: 0.1142
09/16 12:53:21 PM: Update 7355: task edges-ner-ontonotes, batch 355 (7355): mcc: 0.5273, acc: 0.3630, precision: 0.7733, recall: 0.3833, f1: 0.5125, edges-ner-ontonotes_loss: 0.1141
09/16 12:53:31 PM: Update 7429: task edges-ner-ontonotes, batch 429 (7429): mcc: 0.5248, acc: 0.3614, precision: 0.7693, recall: 0.3820, f1: 0.5105, edges-ner-ontonotes_loss: 0.1146
09/16 12:53:41 PM: Update 7479: task edges-ner-ontonotes, batch 479 (7479): mcc: 0.5231, acc: 0.3596, precision: 0.7681, recall: 0.3802, f1: 0.5087, edges-ner-ontonotes_loss: 0.1149
09/16 12:53:51 PM: Update 7544: task edges-ner-ontonotes, batch 544 (7544): mcc: 0.5185, acc: 0.3554, precision: 0.7659, recall: 0.3749, f1: 0.5034, edges-ner-ontonotes_loss: 0.1167
09/16 12:54:02 PM: Update 7623: task edges-ner-ontonotes, batch 623 (7623): mcc: 0.5146, acc: 0.3512, precision: 0.7657, recall: 0.3696, f1: 0.4985, edges-ner-ontonotes_loss: 0.1182
09/16 12:54:14 PM: Update 7699: task edges-ner-ontonotes, batch 699 (7699): mcc: 0.5114, acc: 0.3479, precision: 0.7649, recall: 0.3655, f1: 0.4946, edges-ner-ontonotes_loss: 0.1195
09/16 12:54:24 PM: Update 7749: task edges-ner-ontonotes, batch 749 (7749): mcc: 0.5103, acc: 0.3469, precision: 0.7646, recall: 0.3641, f1: 0.4933, edges-ner-ontonotes_loss: 0.1200
09/16 12:54:34 PM: Update 7798: task edges-ner-ontonotes, batch 798 (7798): mcc: 0.5087, acc: 0.3453, precision: 0.7642, recall: 0.3621, f1: 0.4914, edges-ner-ontonotes_loss: 0.1205
09/16 12:54:44 PM: Update 7867: task edges-ner-ontonotes, batch 867 (7867): mcc: 0.5072, acc: 0.3434, precision: 0.7643, recall: 0.3599, f1: 0.4894, edges-ner-ontonotes_loss: 0.1206
09/16 12:54:57 PM: Update 7970: task edges-ner-ontonotes, batch 970 (7970): mcc: 0.5070, acc: 0.3431, precision: 0.7656, recall: 0.3590, f1: 0.4888, edges-ner-ontonotes_loss: 0.1203
09/16 12:55:02 PM: ***** Step 8000 / Validation 8 *****
09/16 12:55:02 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:55:02 PM: Validating...
09/16 12:55:07 PM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.5140, acc: 0.3142, precision: 0.8820, recall: 0.3157, f1: 0.4650, edges-ner-ontonotes_loss: 0.1204
09/16 12:55:17 PM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.5298, acc: 0.3222, precision: 0.9127, recall: 0.3228, f1: 0.4770, edges-ner-ontonotes_loss: 0.1151
09/16 12:55:27 PM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.5109, acc: 0.3071, precision: 0.8938, recall: 0.3076, f1: 0.4576, edges-ner-ontonotes_loss: 0.1158
09/16 12:55:32 PM: Updating LR scheduler:
09/16 12:55:32 PM: 	Best result seen so far for macro_avg: 0.495
09/16 12:55:32 PM: 	# validation passes without improvement: 1
09/16 12:55:32 PM: edges-ner-ontonotes_loss: training: 0.120147 validation: 0.116414
09/16 12:55:32 PM: macro_avg: validation: 0.448822
09/16 12:55:32 PM: micro_avg: validation: 0.000000
09/16 12:55:32 PM: edges-ner-ontonotes_mcc: training: 0.507752 validation: 0.503947
09/16 12:55:32 PM: edges-ner-ontonotes_acc: training: 0.343726 validation: 0.299287
09/16 12:55:32 PM: edges-ner-ontonotes_precision: training: 0.766769 validation: 0.892930
09/16 12:55:32 PM: edges-ner-ontonotes_recall: training: 0.359486 validation: 0.299742
09/16 12:55:32 PM: edges-ner-ontonotes_f1: training: 0.489486 validation: 0.448822
09/16 12:55:32 PM: Global learning rate: 0.0001
09/16 12:55:32 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:55:38 PM: Update 8046: task edges-ner-ontonotes, batch 46 (8046): mcc: 0.5132, acc: 0.3377, precision: 0.8030, recall: 0.3489, f1: 0.4864, edges-ner-ontonotes_loss: 0.1173
09/16 12:55:51 PM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.5143, acc: 0.3474, precision: 0.7884, recall: 0.3575, f1: 0.4919, edges-ner-ontonotes_loss: 0.1160
09/16 12:56:01 PM: Update 8187: task edges-ner-ontonotes, batch 187 (8187): mcc: 0.5064, acc: 0.3445, precision: 0.7697, recall: 0.3562, f1: 0.4870, edges-ner-ontonotes_loss: 0.1173
09/16 12:56:11 PM: Update 8256: task edges-ner-ontonotes, batch 256 (8256): mcc: 0.5100, acc: 0.3485, precision: 0.7712, recall: 0.3602, f1: 0.4911, edges-ner-ontonotes_loss: 0.1172
09/16 12:56:21 PM: Update 8341: task edges-ner-ontonotes, batch 341 (8341): mcc: 0.5086, acc: 0.3489, precision: 0.7666, recall: 0.3608, f1: 0.4907, edges-ner-ontonotes_loss: 0.1173
09/16 12:56:35 PM: Update 8407: task edges-ner-ontonotes, batch 407 (8407): mcc: 0.5111, acc: 0.3517, precision: 0.7682, recall: 0.3633, f1: 0.4934, edges-ner-ontonotes_loss: 0.1170
09/16 12:56:45 PM: Update 8495: task edges-ner-ontonotes, batch 495 (8495): mcc: 0.5104, acc: 0.3506, precision: 0.7657, recall: 0.3637, f1: 0.4932, edges-ner-ontonotes_loss: 0.1169
09/16 12:56:55 PM: Update 8564: task edges-ner-ontonotes, batch 564 (8564): mcc: 0.5100, acc: 0.3503, precision: 0.7633, recall: 0.3645, f1: 0.4933, edges-ner-ontonotes_loss: 0.1167
09/16 12:57:05 PM: Update 8621: task edges-ner-ontonotes, batch 621 (8621): mcc: 0.5121, acc: 0.3519, precision: 0.7648, recall: 0.3666, f1: 0.4956, edges-ner-ontonotes_loss: 0.1164
09/16 12:57:16 PM: Update 8688: task edges-ner-ontonotes, batch 688 (8688): mcc: 0.5132, acc: 0.3525, precision: 0.7653, recall: 0.3678, f1: 0.4969, edges-ner-ontonotes_loss: 0.1163
09/16 12:57:26 PM: Update 8734: task edges-ner-ontonotes, batch 734 (8734): mcc: 0.5141, acc: 0.3531, precision: 0.7653, recall: 0.3690, f1: 0.4980, edges-ner-ontonotes_loss: 0.1161
09/16 12:57:36 PM: Update 8796: task edges-ner-ontonotes, batch 796 (8796): mcc: 0.5147, acc: 0.3535, precision: 0.7651, recall: 0.3701, f1: 0.4988, edges-ner-ontonotes_loss: 0.1159
09/16 12:57:46 PM: Update 8862: task edges-ner-ontonotes, batch 862 (8862): mcc: 0.5162, acc: 0.3551, precision: 0.7656, recall: 0.3719, f1: 0.5006, edges-ner-ontonotes_loss: 0.1156
09/16 12:57:56 PM: Update 8937: task edges-ner-ontonotes, batch 937 (8937): mcc: 0.5177, acc: 0.3567, precision: 0.7663, recall: 0.3736, f1: 0.5023, edges-ner-ontonotes_loss: 0.1154
09/16 12:58:08 PM: ***** Step 9000 / Validation 9 *****
09/16 12:58:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:58:08 PM: Validating...
09/16 12:58:08 PM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.6047, acc: 0.4262, precision: 0.8966, recall: 0.4262, f1: 0.5778, edges-ner-ontonotes_loss: 0.1443
09/16 12:58:18 PM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.4728, acc: 0.2790, precision: 0.8381, recall: 0.2836, f1: 0.4238, edges-ner-ontonotes_loss: 0.1256
09/16 12:58:28 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.5283, acc: 0.3299, precision: 0.8695, recall: 0.3384, f1: 0.4872, edges-ner-ontonotes_loss: 0.1160
09/16 12:58:34 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:58:35 PM: Best result seen so far for macro.
09/16 12:58:35 PM: Updating LR scheduler:
09/16 12:58:35 PM: 	Best result seen so far for macro_avg: 0.498
09/16 12:58:35 PM: 	# validation passes without improvement: 0
09/16 12:58:35 PM: edges-ner-ontonotes_loss: training: 0.115431 validation: 0.112347
09/16 12:58:35 PM: macro_avg: validation: 0.497801
09/16 12:58:35 PM: micro_avg: validation: 0.000000
09/16 12:58:35 PM: edges-ner-ontonotes_mcc: training: 0.517802 validation: 0.537870
09/16 12:58:35 PM: edges-ner-ontonotes_acc: training: 0.356764 validation: 0.338793
09/16 12:58:35 PM: edges-ner-ontonotes_precision: training: 0.766255 validation: 0.876170
09/16 12:58:35 PM: edges-ner-ontonotes_recall: training: 0.373744 validation: 0.347665
09/16 12:58:35 PM: edges-ner-ontonotes_f1: training: 0.502427 validation: 0.497801
09/16 12:58:35 PM: Global learning rate: 0.0001
09/16 12:58:35 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 12:58:38 PM: Update 9022: task edges-ner-ontonotes, batch 22 (9022): mcc: 0.5175, acc: 0.3545, precision: 0.7579, recall: 0.3778, f1: 0.5042, edges-ner-ontonotes_loss: 0.1132
09/16 12:58:48 PM: Update 9057: task edges-ner-ontonotes, batch 57 (9057): mcc: 0.4965, acc: 0.3445, precision: 0.7314, recall: 0.3626, f1: 0.4848, edges-ner-ontonotes_loss: 0.1223
09/16 12:58:58 PM: Update 9123: task edges-ner-ontonotes, batch 123 (9123): mcc: 0.4904, acc: 0.3304, precision: 0.7494, recall: 0.3445, f1: 0.4721, edges-ner-ontonotes_loss: 0.1262
09/16 12:59:08 PM: Update 9189: task edges-ner-ontonotes, batch 189 (9189): mcc: 0.4924, acc: 0.3315, precision: 0.7549, recall: 0.3445, f1: 0.4731, edges-ner-ontonotes_loss: 0.1262
09/16 12:59:18 PM: Update 9261: task edges-ner-ontonotes, batch 261 (9261): mcc: 0.4888, acc: 0.3280, precision: 0.7538, recall: 0.3401, f1: 0.4687, edges-ner-ontonotes_loss: 0.1276
09/16 12:59:28 PM: Update 9317: task edges-ner-ontonotes, batch 317 (9317): mcc: 0.4892, acc: 0.3286, precision: 0.7544, recall: 0.3404, f1: 0.4691, edges-ner-ontonotes_loss: 0.1275
09/16 12:59:39 PM: Update 9337: task edges-ner-ontonotes, batch 337 (9337): mcc: 0.4896, acc: 0.3289, precision: 0.7552, recall: 0.3405, f1: 0.4694, edges-ner-ontonotes_loss: 0.1273
09/16 12:59:49 PM: Update 9426: task edges-ner-ontonotes, batch 426 (9426): mcc: 0.4891, acc: 0.3276, precision: 0.7566, recall: 0.3391, f1: 0.4683, edges-ner-ontonotes_loss: 0.1258
09/16 12:59:59 PM: Update 9501: task edges-ner-ontonotes, batch 501 (9501): mcc: 0.4911, acc: 0.3293, precision: 0.7585, recall: 0.3409, f1: 0.4704, edges-ner-ontonotes_loss: 0.1245
09/16 01:00:09 PM: Update 9570: task edges-ner-ontonotes, batch 570 (9570): mcc: 0.4936, acc: 0.3313, precision: 0.7617, recall: 0.3426, f1: 0.4727, edges-ner-ontonotes_loss: 0.1238
09/16 01:00:19 PM: Update 9630: task edges-ner-ontonotes, batch 630 (9630): mcc: 0.4957, acc: 0.3334, precision: 0.7638, recall: 0.3445, f1: 0.4749, edges-ner-ontonotes_loss: 0.1232
09/16 01:00:29 PM: Update 9669: task edges-ner-ontonotes, batch 669 (9669): mcc: 0.4961, acc: 0.3337, precision: 0.7645, recall: 0.3447, f1: 0.4751, edges-ner-ontonotes_loss: 0.1229
09/16 01:00:39 PM: Update 9752: task edges-ner-ontonotes, batch 752 (9752): mcc: 0.4942, acc: 0.3326, precision: 0.7612, recall: 0.3438, f1: 0.4737, edges-ner-ontonotes_loss: 0.1228
09/16 01:00:49 PM: Update 9814: task edges-ner-ontonotes, batch 814 (9814): mcc: 0.4956, acc: 0.3342, precision: 0.7616, recall: 0.3454, f1: 0.4753, edges-ner-ontonotes_loss: 0.1224
09/16 01:00:59 PM: Update 9886: task edges-ner-ontonotes, batch 886 (9886): mcc: 0.4986, acc: 0.3372, precision: 0.7636, recall: 0.3485, f1: 0.4786, edges-ner-ontonotes_loss: 0.1217
09/16 01:01:12 PM: Update 9963: task edges-ner-ontonotes, batch 963 (9963): mcc: 0.5013, acc: 0.3399, precision: 0.7648, recall: 0.3517, f1: 0.4818, edges-ner-ontonotes_loss: 0.1211
09/16 01:01:16 PM: ***** Step 10000 / Validation 10 *****
09/16 01:01:16 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:01:16 PM: Validating...
09/16 01:01:22 PM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.4621, acc: 0.2803, precision: 0.8037, recall: 0.2839, f1: 0.4196, edges-ner-ontonotes_loss: 0.1262
09/16 01:01:32 PM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.5147, acc: 0.3191, precision: 0.8559, recall: 0.3272, f1: 0.4734, edges-ner-ontonotes_loss: 0.1180
09/16 01:01:41 PM: Updating LR scheduler:
09/16 01:01:41 PM: 	Best result seen so far for macro_avg: 0.498
09/16 01:01:41 PM: 	# validation passes without improvement: 1
09/16 01:01:41 PM: edges-ner-ontonotes_loss: training: 0.120798 validation: 0.114389
09/16 01:01:41 PM: macro_avg: validation: 0.486596
09/16 01:01:41 PM: micro_avg: validation: 0.000000
09/16 01:01:41 PM: edges-ner-ontonotes_mcc: training: 0.501709 validation: 0.526726
09/16 01:01:41 PM: edges-ner-ontonotes_acc: training: 0.340139 validation: 0.330149
09/16 01:01:41 PM: edges-ner-ontonotes_precision: training: 0.764263 validation: 0.864640
09/16 01:01:41 PM: edges-ner-ontonotes_recall: training: 0.352465 validation: 0.338565
09/16 01:01:41 PM: edges-ner-ontonotes_f1: training: 0.482438 validation: 0.486596
09/16 01:01:41 PM: Global learning rate: 0.0001
09/16 01:01:41 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:01:43 PM: Update 10024: task edges-ner-ontonotes, batch 24 (10024): mcc: 0.5033, acc: 0.3358, precision: 0.7584, recall: 0.3577, f1: 0.4861, edges-ner-ontonotes_loss: 0.1162
09/16 01:01:53 PM: Update 10093: task edges-ner-ontonotes, batch 93 (10093): mcc: 0.5161, acc: 0.3523, precision: 0.7627, recall: 0.3733, f1: 0.5013, edges-ner-ontonotes_loss: 0.1156
09/16 01:02:04 PM: Update 10158: task edges-ner-ontonotes, batch 158 (10158): mcc: 0.5208, acc: 0.3568, precision: 0.7637, recall: 0.3794, f1: 0.5069, edges-ner-ontonotes_loss: 0.1148
09/16 01:02:14 PM: Update 10215: task edges-ner-ontonotes, batch 215 (10215): mcc: 0.5220, acc: 0.3587, precision: 0.7639, recall: 0.3810, f1: 0.5084, edges-ner-ontonotes_loss: 0.1144
09/16 01:02:28 PM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.5209, acc: 0.3584, precision: 0.7627, recall: 0.3800, f1: 0.5073, edges-ner-ontonotes_loss: 0.1148
09/16 01:02:38 PM: Update 10340: task edges-ner-ontonotes, batch 340 (10340): mcc: 0.5220, acc: 0.3593, precision: 0.7629, recall: 0.3814, f1: 0.5086, edges-ner-ontonotes_loss: 0.1146
09/16 01:02:49 PM: Update 10408: task edges-ner-ontonotes, batch 408 (10408): mcc: 0.5236, acc: 0.3607, precision: 0.7648, recall: 0.3827, f1: 0.5101, edges-ner-ontonotes_loss: 0.1142
09/16 01:02:59 PM: Update 10476: task edges-ner-ontonotes, batch 476 (10476): mcc: 0.5245, acc: 0.3616, precision: 0.7660, recall: 0.3834, f1: 0.5110, edges-ner-ontonotes_loss: 0.1140
09/16 01:03:09 PM: Update 10540: task edges-ner-ontonotes, batch 540 (10540): mcc: 0.5242, acc: 0.3614, precision: 0.7659, recall: 0.3830, f1: 0.5107, edges-ner-ontonotes_loss: 0.1141
09/16 01:03:21 PM: Update 10589: task edges-ner-ontonotes, batch 589 (10589): mcc: 0.5234, acc: 0.3608, precision: 0.7653, recall: 0.3821, f1: 0.5097, edges-ner-ontonotes_loss: 0.1142
09/16 01:03:31 PM: Update 10661: task edges-ner-ontonotes, batch 661 (10661): mcc: 0.5175, acc: 0.3554, precision: 0.7612, recall: 0.3760, f1: 0.5034, edges-ner-ontonotes_loss: 0.1162
09/16 01:03:41 PM: Update 10719: task edges-ner-ontonotes, batch 719 (10719): mcc: 0.5146, acc: 0.3524, precision: 0.7603, recall: 0.3724, f1: 0.4999, edges-ner-ontonotes_loss: 0.1172
09/16 01:03:51 PM: Update 10789: task edges-ner-ontonotes, batch 789 (10789): mcc: 0.5129, acc: 0.3509, precision: 0.7600, recall: 0.3702, f1: 0.4979, edges-ner-ontonotes_loss: 0.1180
09/16 01:04:02 PM: Update 10857: task edges-ner-ontonotes, batch 857 (10857): mcc: 0.5119, acc: 0.3499, precision: 0.7606, recall: 0.3685, f1: 0.4965, edges-ner-ontonotes_loss: 0.1185
09/16 01:04:13 PM: Update 10893: task edges-ner-ontonotes, batch 893 (10893): mcc: 0.5116, acc: 0.3497, precision: 0.7606, recall: 0.3680, f1: 0.4960, edges-ner-ontonotes_loss: 0.1189
09/16 01:04:23 PM: Update 10963: task edges-ner-ontonotes, batch 963 (10963): mcc: 0.5105, acc: 0.3481, precision: 0.7614, recall: 0.3660, f1: 0.4944, edges-ner-ontonotes_loss: 0.1191
09/16 01:04:29 PM: ***** Step 11000 / Validation 11 *****
09/16 01:04:30 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:04:30 PM: Validating...
09/16 01:04:33 PM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.4889, acc: 0.2983, precision: 0.8457, recall: 0.2997, f1: 0.4426, edges-ner-ontonotes_loss: 0.1242
09/16 01:04:43 PM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.5257, acc: 0.3203, precision: 0.9045, recall: 0.3211, f1: 0.4740, edges-ner-ontonotes_loss: 0.1133
09/16 01:04:54 PM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.5260, acc: 0.3220, precision: 0.9002, recall: 0.3232, f1: 0.4756, edges-ner-ontonotes_loss: 0.1119
09/16 01:04:59 PM: Updating LR scheduler:
09/16 01:04:59 PM: 	Best result seen so far for macro_avg: 0.498
09/16 01:04:59 PM: 	# validation passes without improvement: 2
09/16 01:04:59 PM: edges-ner-ontonotes_loss: training: 0.118980 validation: 0.111992
09/16 01:04:59 PM: macro_avg: validation: 0.474402
09/16 01:04:59 PM: micro_avg: validation: 0.000000
09/16 01:04:59 PM: edges-ner-ontonotes_mcc: training: 0.511011 validation: 0.525544
09/16 01:04:59 PM: edges-ner-ontonotes_acc: training: 0.348525 validation: 0.320594
09/16 01:04:59 PM: edges-ner-ontonotes_precision: training: 0.762478 validation: 0.902211
09/16 01:04:59 PM: edges-ner-ontonotes_recall: training: 0.366248 validation: 0.321808
09/16 01:04:59 PM: edges-ner-ontonotes_f1: training: 0.494816 validation: 0.474402
09/16 01:04:59 PM: Global learning rate: 0.0001
09/16 01:04:59 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:05:04 PM: Update 11046: task edges-ner-ontonotes, batch 46 (11046): mcc: 0.5109, acc: 0.3479, precision: 0.7748, recall: 0.3597, f1: 0.4913, edges-ner-ontonotes_loss: 0.1165
09/16 01:05:15 PM: Update 11113: task edges-ner-ontonotes, batch 113 (11113): mcc: 0.5116, acc: 0.3488, precision: 0.7776, recall: 0.3593, f1: 0.4915, edges-ner-ontonotes_loss: 0.1161
09/16 01:05:25 PM: Update 11185: task edges-ner-ontonotes, batch 185 (11185): mcc: 0.5184, acc: 0.3553, precision: 0.7822, recall: 0.3661, f1: 0.4988, edges-ner-ontonotes_loss: 0.1155
09/16 01:05:35 PM: Update 11230: task edges-ner-ontonotes, batch 230 (11230): mcc: 0.5148, acc: 0.3530, precision: 0.7777, recall: 0.3636, f1: 0.4956, edges-ner-ontonotes_loss: 0.1157
09/16 01:05:45 PM: Update 11304: task edges-ner-ontonotes, batch 304 (11304): mcc: 0.5123, acc: 0.3525, precision: 0.7709, recall: 0.3636, f1: 0.4941, edges-ner-ontonotes_loss: 0.1162
09/16 01:05:55 PM: Update 11362: task edges-ner-ontonotes, batch 362 (11362): mcc: 0.5122, acc: 0.3523, precision: 0.7705, recall: 0.3637, f1: 0.4942, edges-ner-ontonotes_loss: 0.1163
09/16 01:06:05 PM: Update 11443: task edges-ner-ontonotes, batch 443 (11443): mcc: 0.5110, acc: 0.3515, precision: 0.7679, recall: 0.3633, f1: 0.4933, edges-ner-ontonotes_loss: 0.1164
09/16 01:06:18 PM: Update 11519: task edges-ner-ontonotes, batch 519 (11519): mcc: 0.5146, acc: 0.3552, precision: 0.7698, recall: 0.3673, f1: 0.4973, edges-ner-ontonotes_loss: 0.1159
09/16 01:06:28 PM: Update 11606: task edges-ner-ontonotes, batch 606 (11606): mcc: 0.5149, acc: 0.3548, precision: 0.7670, recall: 0.3693, f1: 0.4986, edges-ner-ontonotes_loss: 0.1160
09/16 01:06:38 PM: Update 11699: task edges-ner-ontonotes, batch 699 (11699): mcc: 0.5146, acc: 0.3537, precision: 0.7665, recall: 0.3691, f1: 0.4983, edges-ner-ontonotes_loss: 0.1160
09/16 01:06:49 PM: Update 11774: task edges-ner-ontonotes, batch 774 (11774): mcc: 0.5165, acc: 0.3552, precision: 0.7671, recall: 0.3714, f1: 0.5005, edges-ner-ontonotes_loss: 0.1156
09/16 01:07:01 PM: Update 11832: task edges-ner-ontonotes, batch 832 (11832): mcc: 0.5179, acc: 0.3570, precision: 0.7670, recall: 0.3734, f1: 0.5023, edges-ner-ontonotes_loss: 0.1154
09/16 01:07:11 PM: Update 11892: task edges-ner-ontonotes, batch 892 (11892): mcc: 0.5184, acc: 0.3574, precision: 0.7669, recall: 0.3742, f1: 0.5030, edges-ner-ontonotes_loss: 0.1153
09/16 01:07:22 PM: Update 11961: task edges-ner-ontonotes, batch 961 (11961): mcc: 0.5196, acc: 0.3585, precision: 0.7671, recall: 0.3758, f1: 0.5045, edges-ner-ontonotes_loss: 0.1151
09/16 01:07:29 PM: ***** Step 12000 / Validation 12 *****
09/16 01:07:29 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:07:29 PM: Validating...
09/16 01:07:32 PM: Evaluate: task edges-ner-ontonotes, batch 21 (157): mcc: 0.4344, acc: 0.2666, precision: 0.7565, recall: 0.2689, f1: 0.3968, edges-ner-ontonotes_loss: 0.1382
09/16 01:07:42 PM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.4742, acc: 0.2909, precision: 0.8124, recall: 0.2952, f1: 0.4330, edges-ner-ontonotes_loss: 0.1260
09/16 01:07:52 PM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.5310, acc: 0.3395, precision: 0.8600, recall: 0.3460, f1: 0.4934, edges-ner-ontonotes_loss: 0.1159
09/16 01:07:57 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:07:57 PM: Best result seen so far for macro.
09/16 01:07:57 PM: Updating LR scheduler:
09/16 01:07:57 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:07:57 PM: 	# validation passes without improvement: 0
09/16 01:07:57 PM: edges-ner-ontonotes_loss: training: 0.115060 validation: 0.112903
09/16 01:07:57 PM: macro_avg: validation: 0.504682
09/16 01:07:57 PM: micro_avg: validation: 0.000000
09/16 01:07:57 PM: edges-ner-ontonotes_mcc: training: 0.519588 validation: 0.541697
09/16 01:07:57 PM: edges-ner-ontonotes_acc: training: 0.358674 validation: 0.349105
09/16 01:07:57 PM: edges-ner-ontonotes_precision: training: 0.766283 validation: 0.869299
09/16 01:07:57 PM: edges-ner-ontonotes_recall: training: 0.376242 validation: 0.355550
09/16 01:07:57 PM: edges-ner-ontonotes_f1: training: 0.504685 validation: 0.504682
09/16 01:07:57 PM: Global learning rate: 0.0001
09/16 01:07:57 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:08:02 PM: Update 12031: task edges-ner-ontonotes, batch 31 (12031): mcc: 0.5170, acc: 0.3518, precision: 0.7639, recall: 0.3739, f1: 0.5021, edges-ner-ontonotes_loss: 0.1147
09/16 01:08:12 PM: Update 12114: task edges-ner-ontonotes, batch 114 (12114): mcc: 0.5304, acc: 0.3669, precision: 0.7748, recall: 0.3870, f1: 0.5161, edges-ner-ontonotes_loss: 0.1115
09/16 01:08:22 PM: Update 12149: task edges-ner-ontonotes, batch 149 (12149): mcc: 0.5252, acc: 0.3636, precision: 0.7651, recall: 0.3849, f1: 0.5121, edges-ner-ontonotes_loss: 0.1134
09/16 01:08:32 PM: Update 12223: task edges-ner-ontonotes, batch 223 (12223): mcc: 0.5107, acc: 0.3494, precision: 0.7581, recall: 0.3681, f1: 0.4956, edges-ner-ontonotes_loss: 0.1190
09/16 01:08:42 PM: Update 12296: task edges-ner-ontonotes, batch 296 (12296): mcc: 0.5050, acc: 0.3433, precision: 0.7580, recall: 0.3602, f1: 0.4884, edges-ner-ontonotes_loss: 0.1213
09/16 01:08:52 PM: Update 12365: task edges-ner-ontonotes, batch 365 (12365): mcc: 0.5062, acc: 0.3437, precision: 0.7617, recall: 0.3599, f1: 0.4889, edges-ner-ontonotes_loss: 0.1220
09/16 01:09:02 PM: Update 12433: task edges-ner-ontonotes, batch 433 (12433): mcc: 0.5051, acc: 0.3429, precision: 0.7613, recall: 0.3586, f1: 0.4876, edges-ner-ontonotes_loss: 0.1227
09/16 01:09:12 PM: Update 12481: task edges-ner-ontonotes, batch 481 (12481): mcc: 0.5030, acc: 0.3413, precision: 0.7600, recall: 0.3565, f1: 0.4853, edges-ner-ontonotes_loss: 0.1226
09/16 01:09:23 PM: Update 12553: task edges-ner-ontonotes, batch 553 (12553): mcc: 0.5028, acc: 0.3405, precision: 0.7613, recall: 0.3555, f1: 0.4847, edges-ner-ontonotes_loss: 0.1220
09/16 01:09:33 PM: Update 12626: task edges-ner-ontonotes, batch 626 (12626): mcc: 0.5038, acc: 0.3412, precision: 0.7635, recall: 0.3557, f1: 0.4853, edges-ner-ontonotes_loss: 0.1214
09/16 01:09:43 PM: Update 12709: task edges-ner-ontonotes, batch 709 (12709): mcc: 0.5065, acc: 0.3435, precision: 0.7665, recall: 0.3579, f1: 0.4879, edges-ner-ontonotes_loss: 0.1206
09/16 01:09:56 PM: Update 12762: task edges-ner-ontonotes, batch 762 (12762): mcc: 0.5074, acc: 0.3447, precision: 0.7668, recall: 0.3590, f1: 0.4890, edges-ner-ontonotes_loss: 0.1203
09/16 01:10:06 PM: Update 12829: task edges-ner-ontonotes, batch 829 (12829): mcc: 0.5057, acc: 0.3431, precision: 0.7652, recall: 0.3574, f1: 0.4872, edges-ner-ontonotes_loss: 0.1202
09/16 01:10:16 PM: Update 12897: task edges-ner-ontonotes, batch 897 (12897): mcc: 0.5067, acc: 0.3444, precision: 0.7656, recall: 0.3586, f1: 0.4884, edges-ner-ontonotes_loss: 0.1199
09/16 01:10:26 PM: Update 12957: task edges-ner-ontonotes, batch 957 (12957): mcc: 0.5078, acc: 0.3456, precision: 0.7667, recall: 0.3596, f1: 0.4896, edges-ner-ontonotes_loss: 0.1196
09/16 01:10:33 PM: ***** Step 13000 / Validation 13 *****
09/16 01:10:33 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:10:33 PM: Validating...
09/16 01:10:36 PM: Evaluate: task edges-ner-ontonotes, batch 26 (157): mcc: 0.4724, acc: 0.2843, precision: 0.8297, recall: 0.2862, f1: 0.4256, edges-ner-ontonotes_loss: 0.1265
09/16 01:10:47 PM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.5380, acc: 0.3369, precision: 0.8964, recall: 0.3393, f1: 0.4923, edges-ner-ontonotes_loss: 0.1117
09/16 01:10:57 PM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.5333, acc: 0.3312, precision: 0.8907, recall: 0.3359, f1: 0.4878, edges-ner-ontonotes_loss: 0.1096
09/16 01:11:01 PM: Updating LR scheduler:
09/16 01:11:01 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:11:01 PM: 	# validation passes without improvement: 1
09/16 01:11:01 PM: edges-ner-ontonotes_loss: training: 0.119470 validation: 0.109895
09/16 01:11:01 PM: macro_avg: validation: 0.482217
09/16 01:11:01 PM: micro_avg: validation: 0.000000
09/16 01:11:01 PM: edges-ner-ontonotes_mcc: training: 0.508171 validation: 0.529150
09/16 01:11:01 PM: edges-ner-ontonotes_acc: training: 0.346156 validation: 0.325827
09/16 01:11:01 PM: edges-ner-ontonotes_precision: training: 0.766840 validation: 0.891229
09/16 01:11:01 PM: edges-ner-ontonotes_recall: training: 0.360028 validation: 0.330528
09/16 01:11:01 PM: edges-ner-ontonotes_f1: training: 0.490002 validation: 0.482217
09/16 01:11:01 PM: Global learning rate: 0.0001
09/16 01:11:01 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:11:07 PM: Update 13040: task edges-ner-ontonotes, batch 40 (13040): mcc: 0.5318, acc: 0.3766, precision: 0.7753, recall: 0.3886, f1: 0.5177, edges-ner-ontonotes_loss: 0.1122
09/16 01:11:22 PM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.5277, acc: 0.3704, precision: 0.7762, recall: 0.3824, f1: 0.5124, edges-ner-ontonotes_loss: 0.1143
09/16 01:11:32 PM: Update 13162: task edges-ner-ontonotes, batch 162 (13162): mcc: 0.5209, acc: 0.3602, precision: 0.7643, recall: 0.3792, f1: 0.5069, edges-ner-ontonotes_loss: 0.1148
09/16 01:11:42 PM: Update 13249: task edges-ner-ontonotes, batch 249 (13249): mcc: 0.5223, acc: 0.3591, precision: 0.7686, recall: 0.3788, f1: 0.5075, edges-ner-ontonotes_loss: 0.1144
09/16 01:11:52 PM: Update 13335: task edges-ner-ontonotes, batch 335 (13335): mcc: 0.5247, acc: 0.3618, precision: 0.7678, recall: 0.3826, f1: 0.5107, edges-ner-ontonotes_loss: 0.1138
09/16 01:12:08 PM: Update 13388: task edges-ner-ontonotes, batch 388 (13388): mcc: 0.5263, acc: 0.3630, precision: 0.7694, recall: 0.3841, f1: 0.5124, edges-ner-ontonotes_loss: 0.1136
09/16 01:12:18 PM: Update 13453: task edges-ner-ontonotes, batch 453 (13453): mcc: 0.5260, acc: 0.3631, precision: 0.7676, recall: 0.3846, f1: 0.5124, edges-ner-ontonotes_loss: 0.1136
09/16 01:12:28 PM: Update 13520: task edges-ner-ontonotes, batch 520 (13520): mcc: 0.5266, acc: 0.3634, precision: 0.7686, recall: 0.3848, f1: 0.5129, edges-ner-ontonotes_loss: 0.1133
09/16 01:12:38 PM: Update 13582: task edges-ner-ontonotes, batch 582 (13582): mcc: 0.5269, acc: 0.3638, precision: 0.7687, recall: 0.3853, f1: 0.5133, edges-ner-ontonotes_loss: 0.1133
09/16 01:12:49 PM: Update 13653: task edges-ner-ontonotes, batch 653 (13653): mcc: 0.5269, acc: 0.3639, precision: 0.7686, recall: 0.3853, f1: 0.5133, edges-ner-ontonotes_loss: 0.1132
09/16 01:13:00 PM: Update 13701: task edges-ner-ontonotes, batch 701 (13701): mcc: 0.5270, acc: 0.3643, precision: 0.7680, recall: 0.3858, f1: 0.5136, edges-ner-ontonotes_loss: 0.1131
09/16 01:13:10 PM: Update 13769: task edges-ner-ontonotes, batch 769 (13769): mcc: 0.5227, acc: 0.3607, precision: 0.7643, recall: 0.3818, f1: 0.5092, edges-ner-ontonotes_loss: 0.1147
09/16 01:13:20 PM: Update 13837: task edges-ner-ontonotes, batch 837 (13837): mcc: 0.5197, acc: 0.3578, precision: 0.7630, recall: 0.3781, f1: 0.5057, edges-ner-ontonotes_loss: 0.1159
09/16 01:13:30 PM: Update 13897: task edges-ner-ontonotes, batch 897 (13897): mcc: 0.5185, acc: 0.3566, precision: 0.7630, recall: 0.3764, f1: 0.5041, edges-ner-ontonotes_loss: 0.1166
09/16 01:13:42 PM: Update 13964: task edges-ner-ontonotes, batch 964 (13964): mcc: 0.5167, acc: 0.3549, precision: 0.7628, recall: 0.3740, f1: 0.5019, edges-ner-ontonotes_loss: 0.1171
09/16 01:13:46 PM: ***** Step 14000 / Validation 14 *****
09/16 01:13:46 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:13:46 PM: Validating...
09/16 01:13:52 PM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.5054, acc: 0.3081, precision: 0.8732, recall: 0.3089, f1: 0.4563, edges-ner-ontonotes_loss: 0.1175
09/16 01:14:02 PM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.5153, acc: 0.3115, precision: 0.8936, recall: 0.3128, f1: 0.4634, edges-ner-ontonotes_loss: 0.1137
09/16 01:14:12 PM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.5210, acc: 0.3176, precision: 0.8920, recall: 0.3203, f1: 0.4714, edges-ner-ontonotes_loss: 0.1108
09/16 01:14:15 PM: Updating LR scheduler:
09/16 01:14:15 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:14:15 PM: 	# validation passes without improvement: 2
09/16 01:14:15 PM: edges-ner-ontonotes_loss: training: 0.117474 validation: 0.110832
09/16 01:14:15 PM: macro_avg: validation: 0.470299
09/16 01:14:15 PM: micro_avg: validation: 0.000000
09/16 01:14:15 PM: edges-ner-ontonotes_mcc: training: 0.516193 validation: 0.520609
09/16 01:14:15 PM: edges-ner-ontonotes_acc: training: 0.354294 validation: 0.316272
09/16 01:14:15 PM: edges-ner-ontonotes_precision: training: 0.763195 validation: 0.893988
09/16 01:14:15 PM: edges-ner-ontonotes_recall: training: 0.373123 validation: 0.319078
09/16 01:14:15 PM: edges-ner-ontonotes_f1: training: 0.501208 validation: 0.470299
09/16 01:14:15 PM: Global learning rate: 0.0001
09/16 01:14:15 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:14:23 PM: Update 14010: task edges-ner-ontonotes, batch 10 (14010): mcc: 0.4671, acc: 0.3122, precision: 0.7426, recall: 0.3165, f1: 0.4438, edges-ner-ontonotes_loss: 0.1203
09/16 01:14:33 PM: Update 14082: task edges-ner-ontonotes, batch 82 (14082): mcc: 0.4940, acc: 0.3328, precision: 0.7650, recall: 0.3416, f1: 0.4723, edges-ner-ontonotes_loss: 0.1196
09/16 01:14:43 PM: Update 14152: task edges-ner-ontonotes, batch 152 (14152): mcc: 0.5022, acc: 0.3389, precision: 0.7719, recall: 0.3493, f1: 0.4810, edges-ner-ontonotes_loss: 0.1185
09/16 01:14:53 PM: Update 14226: task edges-ner-ontonotes, batch 226 (14226): mcc: 0.5087, acc: 0.3448, precision: 0.7767, recall: 0.3558, f1: 0.4880, edges-ner-ontonotes_loss: 0.1175
09/16 01:15:03 PM: Update 14296: task edges-ner-ontonotes, batch 296 (14296): mcc: 0.5137, acc: 0.3496, precision: 0.7799, recall: 0.3610, f1: 0.4935, edges-ner-ontonotes_loss: 0.1164
09/16 01:15:14 PM: Update 14331: task edges-ner-ontonotes, batch 331 (14331): mcc: 0.5114, acc: 0.3477, precision: 0.7764, recall: 0.3596, f1: 0.4915, edges-ner-ontonotes_loss: 0.1167
09/16 01:15:24 PM: Update 14394: task edges-ner-ontonotes, batch 394 (14394): mcc: 0.5099, acc: 0.3476, precision: 0.7723, recall: 0.3595, f1: 0.4907, edges-ner-ontonotes_loss: 0.1172
09/16 01:15:34 PM: Update 14470: task edges-ner-ontonotes, batch 470 (14470): mcc: 0.5105, acc: 0.3490, precision: 0.7708, recall: 0.3612, f1: 0.4919, edges-ner-ontonotes_loss: 0.1171
09/16 01:15:44 PM: Update 14540: task edges-ner-ontonotes, batch 540 (14540): mcc: 0.5121, acc: 0.3501, precision: 0.7723, recall: 0.3627, f1: 0.4936, edges-ner-ontonotes_loss: 0.1166
09/16 01:15:54 PM: Update 14610: task edges-ner-ontonotes, batch 610 (14610): mcc: 0.5139, acc: 0.3525, precision: 0.7721, recall: 0.3653, f1: 0.4959, edges-ner-ontonotes_loss: 0.1162
09/16 01:16:04 PM: Update 14652: task edges-ner-ontonotes, batch 652 (14652): mcc: 0.5145, acc: 0.3533, precision: 0.7716, recall: 0.3663, f1: 0.4968, edges-ner-ontonotes_loss: 0.1162
09/16 01:16:14 PM: Update 14736: task edges-ner-ontonotes, batch 736 (14736): mcc: 0.5142, acc: 0.3531, precision: 0.7678, recall: 0.3679, f1: 0.4974, edges-ner-ontonotes_loss: 0.1160
09/16 01:16:24 PM: Update 14814: task edges-ner-ontonotes, batch 814 (14814): mcc: 0.5144, acc: 0.3531, precision: 0.7669, recall: 0.3687, f1: 0.4980, edges-ner-ontonotes_loss: 0.1158
09/16 01:16:34 PM: Update 14902: task edges-ner-ontonotes, batch 902 (14902): mcc: 0.5164, acc: 0.3551, precision: 0.7671, recall: 0.3714, f1: 0.5004, edges-ner-ontonotes_loss: 0.1154
09/16 01:16:44 PM: Update 14967: task edges-ner-ontonotes, batch 967 (14967): mcc: 0.5175, acc: 0.3561, precision: 0.7673, recall: 0.3727, f1: 0.5017, edges-ner-ontonotes_loss: 0.1152
09/16 01:16:49 PM: ***** Step 15000 / Validation 15 *****
09/16 01:16:49 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:16:49 PM: Validating...
09/16 01:16:54 PM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.4670, acc: 0.2852, precision: 0.8046, recall: 0.2895, f1: 0.4258, edges-ner-ontonotes_loss: 0.1276
09/16 01:17:05 PM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.5189, acc: 0.3255, precision: 0.8572, recall: 0.3319, f1: 0.4785, edges-ner-ontonotes_loss: 0.1187
09/16 01:17:14 PM: Updating LR scheduler:
09/16 01:17:14 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:17:14 PM: 	# validation passes without improvement: 3
09/16 01:17:14 PM: edges-ner-ontonotes_loss: training: 0.115160 validation: 0.112184
09/16 01:17:14 PM: macro_avg: validation: 0.503147
09/16 01:17:14 PM: micro_avg: validation: 0.000000
09/16 01:17:14 PM: edges-ner-ontonotes_mcc: training: 0.517753 validation: 0.539814
09/16 01:17:14 PM: edges-ner-ontonotes_acc: training: 0.356197 validation: 0.346148
09/16 01:17:14 PM: edges-ner-ontonotes_precision: training: 0.767109 validation: 0.866086
09/16 01:17:14 PM: edges-ner-ontonotes_recall: training: 0.373218 validation: 0.354565
09/16 01:17:14 PM: edges-ner-ontonotes_f1: training: 0.502135 validation: 0.503147
09/16 01:17:14 PM: Global learning rate: 0.0001
09/16 01:17:14 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:17:15 PM: Update 15002: task edges-ner-ontonotes, batch 2 (15002): mcc: 0.5464, acc: 0.3842, precision: 0.7941, recall: 0.3990, f1: 0.5311, edges-ner-ontonotes_loss: 0.1176
09/16 01:17:25 PM: Update 15069: task edges-ner-ontonotes, batch 69 (15069): mcc: 0.5260, acc: 0.3651, precision: 0.7643, recall: 0.3864, f1: 0.5133, edges-ner-ontonotes_loss: 0.1139
09/16 01:17:35 PM: Update 15151: task edges-ner-ontonotes, batch 151 (15151): mcc: 0.5283, acc: 0.3662, precision: 0.7699, recall: 0.3866, f1: 0.5147, edges-ner-ontonotes_loss: 0.1132
09/16 01:17:45 PM: Update 15230: task edges-ner-ontonotes, batch 230 (15230): mcc: 0.5327, acc: 0.3714, precision: 0.7729, recall: 0.3912, f1: 0.5195, edges-ner-ontonotes_loss: 0.1125
09/16 01:17:55 PM: Update 15257: task edges-ner-ontonotes, batch 257 (15257): mcc: 0.5312, acc: 0.3701, precision: 0.7705, recall: 0.3904, f1: 0.5182, edges-ner-ontonotes_loss: 0.1126
09/16 01:18:05 PM: Update 15319: task edges-ner-ontonotes, batch 319 (15319): mcc: 0.5205, acc: 0.3603, precision: 0.7631, recall: 0.3792, f1: 0.5067, edges-ner-ontonotes_loss: 0.1159
09/16 01:18:15 PM: Update 15393: task edges-ner-ontonotes, batch 393 (15393): mcc: 0.5162, acc: 0.3553, precision: 0.7625, recall: 0.3735, f1: 0.5014, edges-ner-ontonotes_loss: 0.1180
09/16 01:18:25 PM: Update 15465: task edges-ner-ontonotes, batch 465 (15465): mcc: 0.5134, acc: 0.3525, precision: 0.7626, recall: 0.3695, f1: 0.4978, edges-ner-ontonotes_loss: 0.1192
09/16 01:18:35 PM: Update 15525: task edges-ner-ontonotes, batch 525 (15525): mcc: 0.5117, acc: 0.3504, precision: 0.7629, recall: 0.3670, f1: 0.4956, edges-ner-ontonotes_loss: 0.1202
09/16 01:18:46 PM: Update 15561: task edges-ner-ontonotes, batch 561 (15561): mcc: 0.5109, acc: 0.3500, precision: 0.7619, recall: 0.3664, f1: 0.4948, edges-ner-ontonotes_loss: 0.1205
09/16 01:18:56 PM: Update 15626: task edges-ner-ontonotes, batch 626 (15626): mcc: 0.5107, acc: 0.3491, precision: 0.7635, recall: 0.3652, f1: 0.4941, edges-ner-ontonotes_loss: 0.1202
09/16 01:19:06 PM: Update 15720: task edges-ner-ontonotes, batch 720 (15720): mcc: 0.5097, acc: 0.3477, precision: 0.7639, recall: 0.3636, f1: 0.4927, edges-ner-ontonotes_loss: 0.1200
09/16 01:19:16 PM: Update 15804: task edges-ner-ontonotes, batch 804 (15804): mcc: 0.5111, acc: 0.3486, precision: 0.7660, recall: 0.3645, f1: 0.4939, edges-ner-ontonotes_loss: 0.1196
09/16 01:19:33 PM: Update 15874: task edges-ner-ontonotes, batch 874 (15874): mcc: 0.5120, acc: 0.3495, precision: 0.7672, recall: 0.3651, f1: 0.4948, edges-ner-ontonotes_loss: 0.1191
09/16 01:19:43 PM: Update 15930: task edges-ner-ontonotes, batch 930 (15930): mcc: 0.5113, acc: 0.3490, precision: 0.7665, recall: 0.3645, f1: 0.4941, edges-ner-ontonotes_loss: 0.1189
09/16 01:19:53 PM: Update 15990: task edges-ner-ontonotes, batch 990 (15990): mcc: 0.5118, acc: 0.3495, precision: 0.7670, recall: 0.3650, f1: 0.4946, edges-ner-ontonotes_loss: 0.1187
09/16 01:19:54 PM: ***** Step 16000 / Validation 16 *****
09/16 01:19:54 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:19:54 PM: Validating...
09/16 01:20:05 PM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.5167, acc: 0.3268, precision: 0.8586, recall: 0.3286, f1: 0.4753, edges-ner-ontonotes_loss: 0.1152
09/16 01:20:15 PM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.5268, acc: 0.3299, precision: 0.8780, recall: 0.3331, f1: 0.4829, edges-ner-ontonotes_loss: 0.1139
09/16 01:20:25 PM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.5280, acc: 0.3307, precision: 0.8765, recall: 0.3352, f1: 0.4849, edges-ner-ontonotes_loss: 0.1107
09/16 01:20:27 PM: Updating LR scheduler:
09/16 01:20:27 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:20:27 PM: 	# validation passes without improvement: 0
09/16 01:20:27 PM: edges-ner-ontonotes_loss: training: 0.118670 validation: 0.110683
09/16 01:20:27 PM: macro_avg: validation: 0.484323
09/16 01:20:27 PM: micro_avg: validation: 0.000000
09/16 01:20:27 PM: edges-ner-ontonotes_mcc: training: 0.511821 validation: 0.527879
09/16 01:20:27 PM: edges-ner-ontonotes_acc: training: 0.349447 validation: 0.329921
09/16 01:20:27 PM: edges-ner-ontonotes_precision: training: 0.767187 validation: 0.877961
09/16 01:20:27 PM: edges-ner-ontonotes_recall: training: 0.364900 validation: 0.334395
09/16 01:20:27 PM: edges-ner-ontonotes_f1: training: 0.494567 validation: 0.484323
09/16 01:20:27 PM: Global learning rate: 5e-05
09/16 01:20:27 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:20:35 PM: Update 16052: task edges-ner-ontonotes, batch 52 (16052): mcc: 0.5215, acc: 0.3653, precision: 0.7643, recall: 0.3800, f1: 0.5076, edges-ner-ontonotes_loss: 0.1146
09/16 01:20:45 PM: Update 16110: task edges-ner-ontonotes, batch 110 (16110): mcc: 0.5109, acc: 0.3561, precision: 0.7557, recall: 0.3698, f1: 0.4966, edges-ner-ontonotes_loss: 0.1165
09/16 01:20:59 PM: Update 16187: task edges-ner-ontonotes, batch 187 (16187): mcc: 0.5123, acc: 0.3560, precision: 0.7595, recall: 0.3697, f1: 0.4973, edges-ner-ontonotes_loss: 0.1157
09/16 01:21:09 PM: Update 16249: task edges-ner-ontonotes, batch 249 (16249): mcc: 0.5128, acc: 0.3553, precision: 0.7580, recall: 0.3711, f1: 0.4983, edges-ner-ontonotes_loss: 0.1155
09/16 01:21:19 PM: Update 16320: task edges-ner-ontonotes, batch 320 (16320): mcc: 0.5121, acc: 0.3531, precision: 0.7587, recall: 0.3698, f1: 0.4973, edges-ner-ontonotes_loss: 0.1153
09/16 01:21:29 PM: Update 16409: task edges-ner-ontonotes, batch 409 (16409): mcc: 0.5142, acc: 0.3544, precision: 0.7600, recall: 0.3720, f1: 0.4995, edges-ner-ontonotes_loss: 0.1150
09/16 01:21:39 PM: Update 16493: task edges-ner-ontonotes, batch 493 (16493): mcc: 0.5151, acc: 0.3542, precision: 0.7605, recall: 0.3730, f1: 0.5005, edges-ner-ontonotes_loss: 0.1148
09/16 01:21:49 PM: Update 16537: task edges-ner-ontonotes, batch 537 (16537): mcc: 0.5157, acc: 0.3551, precision: 0.7597, recall: 0.3743, f1: 0.5015, edges-ner-ontonotes_loss: 0.1148
09/16 01:21:59 PM: Update 16617: task edges-ner-ontonotes, batch 617 (16617): mcc: 0.5181, acc: 0.3572, precision: 0.7615, recall: 0.3768, f1: 0.5041, edges-ner-ontonotes_loss: 0.1145
09/16 01:22:09 PM: Update 16698: task edges-ner-ontonotes, batch 698 (16698): mcc: 0.5175, acc: 0.3561, precision: 0.7613, recall: 0.3760, f1: 0.5034, edges-ner-ontonotes_loss: 0.1146
09/16 01:22:19 PM: Update 16768: task edges-ner-ontonotes, batch 768 (16768): mcc: 0.5182, acc: 0.3563, precision: 0.7620, recall: 0.3766, f1: 0.5041, edges-ner-ontonotes_loss: 0.1143
09/16 01:22:30 PM: Update 16813: task edges-ner-ontonotes, batch 813 (16813): mcc: 0.5188, acc: 0.3566, precision: 0.7626, recall: 0.3771, f1: 0.5047, edges-ner-ontonotes_loss: 0.1142
09/16 01:22:40 PM: Update 16878: task edges-ner-ontonotes, batch 878 (16878): mcc: 0.5158, acc: 0.3537, precision: 0.7610, recall: 0.3738, f1: 0.5013, edges-ner-ontonotes_loss: 0.1154
09/16 01:22:51 PM: Update 16945: task edges-ner-ontonotes, batch 945 (16945): mcc: 0.5142, acc: 0.3521, precision: 0.7609, recall: 0.3715, f1: 0.4993, edges-ner-ontonotes_loss: 0.1162
09/16 01:22:59 PM: ***** Step 17000 / Validation 17 *****
09/16 01:22:59 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:22:59 PM: Validating...
09/16 01:23:01 PM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.5046, acc: 0.3148, precision: 0.8530, recall: 0.3159, f1: 0.4611, edges-ner-ontonotes_loss: 0.1294
09/16 01:23:11 PM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.5201, acc: 0.3121, precision: 0.9088, recall: 0.3129, f1: 0.4655, edges-ner-ontonotes_loss: 0.1139
09/16 01:23:21 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.5316, acc: 0.3249, precision: 0.9054, recall: 0.3278, f1: 0.4814, edges-ner-ontonotes_loss: 0.1110
09/16 01:23:27 PM: Updating LR scheduler:
09/16 01:23:27 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:23:27 PM: 	# validation passes without improvement: 1
09/16 01:23:27 PM: edges-ner-ontonotes_loss: training: 0.116552 validation: 0.109835
09/16 01:23:27 PM: macro_avg: validation: 0.479719
09/16 01:23:27 PM: micro_avg: validation: 0.000000
09/16 01:23:27 PM: edges-ner-ontonotes_mcc: training: 0.514104 validation: 0.530863
09/16 01:23:27 PM: edges-ner-ontonotes_acc: training: 0.352231 validation: 0.322338
09/16 01:23:27 PM: edges-ner-ontonotes_precision: training: 0.761192 validation: 0.907920
09/16 01:23:27 PM: edges-ner-ontonotes_recall: training: 0.371262 validation: 0.325978
09/16 01:23:27 PM: edges-ner-ontonotes_f1: training: 0.499096 validation: 0.479719
09/16 01:23:27 PM: Global learning rate: 5e-05
09/16 01:23:27 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:23:31 PM: Update 17038: task edges-ner-ontonotes, batch 38 (17038): mcc: 0.5071, acc: 0.3420, precision: 0.7794, recall: 0.3522, f1: 0.4851, edges-ner-ontonotes_loss: 0.1232
09/16 01:23:43 PM: Update 17098: task edges-ner-ontonotes, batch 98 (17098): mcc: 0.5016, acc: 0.3389, precision: 0.7660, recall: 0.3515, f1: 0.4818, edges-ner-ontonotes_loss: 0.1248
09/16 01:23:53 PM: Update 17156: task edges-ner-ontonotes, batch 156 (17156): mcc: 0.5051, acc: 0.3442, precision: 0.7655, recall: 0.3565, f1: 0.4864, edges-ner-ontonotes_loss: 0.1222
09/16 01:24:03 PM: Update 17241: task edges-ner-ontonotes, batch 241 (17241): mcc: 0.5139, acc: 0.3508, precision: 0.7762, recall: 0.3630, f1: 0.4947, edges-ner-ontonotes_loss: 0.1194
09/16 01:24:13 PM: Update 17319: task edges-ner-ontonotes, batch 319 (17319): mcc: 0.5151, acc: 0.3518, precision: 0.7773, recall: 0.3642, f1: 0.4960, edges-ner-ontonotes_loss: 0.1189
09/16 01:24:23 PM: Update 17394: task edges-ner-ontonotes, batch 394 (17394): mcc: 0.5178, acc: 0.3534, precision: 0.7810, recall: 0.3660, f1: 0.4985, edges-ner-ontonotes_loss: 0.1178
09/16 01:24:33 PM: Update 17441: task edges-ner-ontonotes, batch 441 (17441): mcc: 0.5165, acc: 0.3526, precision: 0.7789, recall: 0.3653, f1: 0.4974, edges-ner-ontonotes_loss: 0.1176
09/16 01:24:43 PM: Update 17521: task edges-ner-ontonotes, batch 521 (17521): mcc: 0.5157, acc: 0.3522, precision: 0.7773, recall: 0.3650, f1: 0.4967, edges-ner-ontonotes_loss: 0.1174
09/16 01:24:53 PM: Update 17605: task edges-ner-ontonotes, batch 605 (17605): mcc: 0.5158, acc: 0.3530, precision: 0.7769, recall: 0.3654, f1: 0.4970, edges-ner-ontonotes_loss: 0.1170
09/16 01:25:04 PM: Update 17670: task edges-ner-ontonotes, batch 670 (17670): mcc: 0.5165, acc: 0.3538, precision: 0.7764, recall: 0.3665, f1: 0.4980, edges-ner-ontonotes_loss: 0.1168
09/16 01:25:17 PM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.5164, acc: 0.3540, precision: 0.7750, recall: 0.3671, f1: 0.4983, edges-ner-ontonotes_loss: 0.1165
09/16 01:25:27 PM: Update 17807: task edges-ner-ontonotes, batch 807 (17807): mcc: 0.5159, acc: 0.3532, precision: 0.7729, recall: 0.3675, f1: 0.4982, edges-ner-ontonotes_loss: 0.1165
09/16 01:25:37 PM: Update 17885: task edges-ner-ontonotes, batch 885 (17885): mcc: 0.5166, acc: 0.3541, precision: 0.7718, recall: 0.3691, f1: 0.4994, edges-ner-ontonotes_loss: 0.1163
09/16 01:25:48 PM: Update 17948: task edges-ner-ontonotes, batch 948 (17948): mcc: 0.5168, acc: 0.3541, precision: 0.7710, recall: 0.3699, f1: 0.4999, edges-ner-ontonotes_loss: 0.1161
09/16 01:25:57 PM: ***** Step 18000 / Validation 18 *****
09/16 01:25:58 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:25:58 PM: Validating...
09/16 01:25:58 PM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.6027, acc: 0.3934, precision: 0.9600, recall: 0.3934, f1: 0.5581, edges-ner-ontonotes_loss: 0.1494
09/16 01:26:08 PM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.4859, acc: 0.3013, precision: 0.8161, recall: 0.3080, f1: 0.4472, edges-ner-ontonotes_loss: 0.1213
09/16 01:26:18 PM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.5244, acc: 0.3344, precision: 0.8457, recall: 0.3439, f1: 0.4889, edges-ner-ontonotes_loss: 0.1166
09/16 01:26:26 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:26:26 PM: Best result seen so far for macro.
09/16 01:26:26 PM: Updating LR scheduler:
09/16 01:26:26 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:26:26 PM: 	# validation passes without improvement: 0
09/16 01:26:26 PM: edges-ner-ontonotes_loss: training: 0.115884 validation: 0.112223
09/16 01:26:26 PM: macro_avg: validation: 0.508871
09/16 01:26:26 PM: micro_avg: validation: 0.000000
09/16 01:26:26 PM: edges-ner-ontonotes_mcc: training: 0.517225 validation: 0.543337
09/16 01:26:26 PM: edges-ner-ontonotes_acc: training: 0.354394 validation: 0.351683
09/16 01:26:26 PM: edges-ner-ontonotes_precision: training: 0.770694 validation: 0.861875
09/16 01:26:26 PM: edges-ner-ontonotes_recall: training: 0.370577 validation: 0.361010
09/16 01:26:26 PM: edges-ner-ontonotes_f1: training: 0.500497 validation: 0.508871
09/16 01:26:26 PM: Global learning rate: 5e-05
09/16 01:26:26 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:26:28 PM: Update 18011: task edges-ner-ontonotes, batch 11 (18011): mcc: 0.5461, acc: 0.3805, precision: 0.7947, recall: 0.3982, f1: 0.5306, edges-ner-ontonotes_loss: 0.1126
09/16 01:26:39 PM: Update 18056: task edges-ner-ontonotes, batch 56 (18056): mcc: 0.5339, acc: 0.3721, precision: 0.7725, recall: 0.3931, f1: 0.5211, edges-ner-ontonotes_loss: 0.1121
09/16 01:26:49 PM: Update 18143: task edges-ner-ontonotes, batch 143 (18143): mcc: 0.5295, acc: 0.3658, precision: 0.7690, recall: 0.3889, f1: 0.5165, edges-ner-ontonotes_loss: 0.1128
09/16 01:26:59 PM: Update 18238: task edges-ner-ontonotes, batch 238 (18238): mcc: 0.5327, acc: 0.3679, precision: 0.7753, recall: 0.3899, f1: 0.5188, edges-ner-ontonotes_loss: 0.1129
09/16 01:27:09 PM: Update 18305: task edges-ner-ontonotes, batch 305 (18305): mcc: 0.5309, acc: 0.3663, precision: 0.7744, recall: 0.3878, f1: 0.5168, edges-ner-ontonotes_loss: 0.1131
09/16 01:27:20 PM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.5298, acc: 0.3665, precision: 0.7716, recall: 0.3879, f1: 0.5162, edges-ner-ontonotes_loss: 0.1131
09/16 01:27:30 PM: Update 18432: task edges-ner-ontonotes, batch 432 (18432): mcc: 0.5224, acc: 0.3596, precision: 0.7671, recall: 0.3798, f1: 0.5081, edges-ner-ontonotes_loss: 0.1156
09/16 01:27:41 PM: Update 18506: task edges-ner-ontonotes, batch 506 (18506): mcc: 0.5179, acc: 0.3550, precision: 0.7656, recall: 0.3742, f1: 0.5027, edges-ner-ontonotes_loss: 0.1173
09/16 01:27:51 PM: Update 18564: task edges-ner-ontonotes, batch 564 (18564): mcc: 0.5153, acc: 0.3529, precision: 0.7644, recall: 0.3712, f1: 0.4998, edges-ner-ontonotes_loss: 0.1183
09/16 01:28:01 PM: Update 18628: task edges-ner-ontonotes, batch 628 (18628): mcc: 0.5143, acc: 0.3518, precision: 0.7646, recall: 0.3697, f1: 0.4984, edges-ner-ontonotes_loss: 0.1189
09/16 01:28:12 PM: Update 18673: task edges-ner-ontonotes, batch 673 (18673): mcc: 0.5136, acc: 0.3512, precision: 0.7638, recall: 0.3691, f1: 0.4977, edges-ner-ontonotes_loss: 0.1192
09/16 01:28:22 PM: Update 18754: task edges-ner-ontonotes, batch 754 (18754): mcc: 0.5133, acc: 0.3506, precision: 0.7654, recall: 0.3679, f1: 0.4970, edges-ner-ontonotes_loss: 0.1189
09/16 01:28:32 PM: Update 18829: task edges-ner-ontonotes, batch 829 (18829): mcc: 0.5132, acc: 0.3501, precision: 0.7671, recall: 0.3669, f1: 0.4964, edges-ner-ontonotes_loss: 0.1187
09/16 01:28:42 PM: Update 18912: task edges-ner-ontonotes, batch 912 (18912): mcc: 0.5139, acc: 0.3506, precision: 0.7683, recall: 0.3672, f1: 0.4969, edges-ner-ontonotes_loss: 0.1182
09/16 01:28:52 PM: Update 18977: task edges-ner-ontonotes, batch 977 (18977): mcc: 0.5150, acc: 0.3515, precision: 0.7703, recall: 0.3678, f1: 0.4978, edges-ner-ontonotes_loss: 0.1178
09/16 01:29:01 PM: ***** Step 19000 / Validation 19 *****
09/16 01:29:01 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:29:01 PM: Validating...
09/16 01:29:02 PM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.5152, acc: 0.3525, precision: 0.8011, recall: 0.3525, f1: 0.4896, edges-ner-ontonotes_loss: 0.1382
09/16 01:29:12 PM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.5286, acc: 0.3206, precision: 0.9134, recall: 0.3212, f1: 0.4753, edges-ner-ontonotes_loss: 0.1107
09/16 01:29:22 PM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.5293, acc: 0.3242, precision: 0.9040, recall: 0.3257, f1: 0.4788, edges-ner-ontonotes_loss: 0.1104
09/16 01:29:29 PM: Updating LR scheduler:
09/16 01:29:29 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:29:29 PM: 	# validation passes without improvement: 1
09/16 01:29:29 PM: edges-ner-ontonotes_loss: training: 0.117864 validation: 0.109169
09/16 01:29:29 PM: macro_avg: validation: 0.478302
09/16 01:29:29 PM: micro_avg: validation: 0.000000
09/16 01:29:29 PM: edges-ner-ontonotes_mcc: training: 0.514701 validation: 0.529746
09/16 01:29:29 PM: edges-ner-ontonotes_acc: training: 0.351214 validation: 0.323097
09/16 01:29:29 PM: edges-ner-ontonotes_precision: training: 0.769922 validation: 0.907780
09/16 01:29:29 PM: edges-ner-ontonotes_recall: training: 0.367469 validation: 0.324689
09/16 01:29:29 PM: edges-ner-ontonotes_f1: training: 0.497494 validation: 0.478302
09/16 01:29:29 PM: Global learning rate: 5e-05
09/16 01:29:29 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:29:33 PM: Update 19022: task edges-ner-ontonotes, batch 22 (19022): mcc: 0.4955, acc: 0.3232, precision: 0.7758, recall: 0.3384, f1: 0.4713, edges-ner-ontonotes_loss: 0.1158
09/16 01:29:43 PM: Update 19103: task edges-ner-ontonotes, batch 103 (19103): mcc: 0.5100, acc: 0.3504, precision: 0.7665, recall: 0.3627, f1: 0.4924, edges-ner-ontonotes_loss: 0.1163
09/16 01:29:53 PM: Update 19167: task edges-ner-ontonotes, batch 167 (19167): mcc: 0.5092, acc: 0.3482, precision: 0.7670, recall: 0.3614, f1: 0.4913, edges-ner-ontonotes_loss: 0.1163
09/16 01:30:03 PM: Update 19242: task edges-ner-ontonotes, batch 242 (19242): mcc: 0.5137, acc: 0.3539, precision: 0.7691, recall: 0.3665, f1: 0.4964, edges-ner-ontonotes_loss: 0.1156
09/16 01:30:17 PM: Update 19299: task edges-ner-ontonotes, batch 299 (19299): mcc: 0.5164, acc: 0.3563, precision: 0.7708, recall: 0.3694, f1: 0.4994, edges-ner-ontonotes_loss: 0.1153
09/16 01:30:27 PM: Update 19359: task edges-ner-ontonotes, batch 359 (19359): mcc: 0.5148, acc: 0.3542, precision: 0.7665, recall: 0.3694, f1: 0.4985, edges-ner-ontonotes_loss: 0.1154
09/16 01:30:37 PM: Update 19428: task edges-ner-ontonotes, batch 428 (19428): mcc: 0.5162, acc: 0.3549, precision: 0.7667, recall: 0.3713, f1: 0.5003, edges-ner-ontonotes_loss: 0.1149
09/16 01:30:47 PM: Update 19494: task edges-ner-ontonotes, batch 494 (19494): mcc: 0.5162, acc: 0.3540, precision: 0.7662, recall: 0.3714, f1: 0.5003, edges-ner-ontonotes_loss: 0.1148
09/16 01:30:57 PM: Update 19590: task edges-ner-ontonotes, batch 590 (19590): mcc: 0.5189, acc: 0.3570, precision: 0.7659, recall: 0.3755, f1: 0.5039, edges-ner-ontonotes_loss: 0.1144
09/16 01:31:08 PM: Update 19650: task edges-ner-ontonotes, batch 650 (19650): mcc: 0.5208, acc: 0.3590, precision: 0.7660, recall: 0.3781, f1: 0.5063, edges-ner-ontonotes_loss: 0.1141
09/16 01:31:18 PM: Update 19714: task edges-ner-ontonotes, batch 714 (19714): mcc: 0.5208, acc: 0.3587, precision: 0.7656, recall: 0.3783, f1: 0.5064, edges-ner-ontonotes_loss: 0.1141
09/16 01:31:28 PM: Update 19794: task edges-ner-ontonotes, batch 794 (19794): mcc: 0.5207, acc: 0.3585, precision: 0.7657, recall: 0.3782, f1: 0.5063, edges-ner-ontonotes_loss: 0.1141
09/16 01:31:38 PM: Update 19871: task edges-ner-ontonotes, batch 871 (19871): mcc: 0.5208, acc: 0.3590, precision: 0.7646, recall: 0.3789, f1: 0.5067, edges-ner-ontonotes_loss: 0.1139
09/16 01:31:51 PM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.5211, acc: 0.3593, precision: 0.7647, recall: 0.3793, f1: 0.5071, edges-ner-ontonotes_loss: 0.1140
09/16 01:32:01 PM: ***** Step 20000 / Validation 20 *****
09/16 01:32:01 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:32:01 PM: Validating...
09/16 01:32:01 PM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.6308, acc: 0.4590, precision: 0.9032, recall: 0.4590, f1: 0.6087, edges-ner-ontonotes_loss: 0.1358
09/16 01:32:11 PM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.5153, acc: 0.3046, precision: 0.9110, recall: 0.3064, f1: 0.4586, edges-ner-ontonotes_loss: 0.1123
09/16 01:32:22 PM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.5322, acc: 0.3237, precision: 0.9063, recall: 0.3282, f1: 0.4819, edges-ner-ontonotes_loss: 0.1096
09/16 01:32:28 PM: Updating LR scheduler:
09/16 01:32:28 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:32:28 PM: 	# validation passes without improvement: 2
09/16 01:32:28 PM: edges-ner-ontonotes_loss: training: 0.115202 validation: 0.107804
09/16 01:32:28 PM: macro_avg: validation: 0.488741
09/16 01:32:28 PM: micro_avg: validation: 0.000000
09/16 01:32:28 PM: edges-ner-ontonotes_mcc: training: 0.518445 validation: 0.538233
09/16 01:32:28 PM: edges-ner-ontonotes_acc: training: 0.356850 validation: 0.328935
09/16 01:32:28 PM: edges-ner-ontonotes_precision: training: 0.762770 validation: 0.909955
09/16 01:32:28 PM: edges-ner-ontonotes_recall: training: 0.376527 validation: 0.334092
09/16 01:32:28 PM: edges-ner-ontonotes_f1: training: 0.504177 validation: 0.488741
09/16 01:32:28 PM: Global learning rate: 5e-05
09/16 01:32:28 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:32:32 PM: Update 20026: task edges-ner-ontonotes, batch 26 (20026): mcc: 0.4930, acc: 0.3257, precision: 0.7680, recall: 0.3387, f1: 0.4701, edges-ner-ontonotes_loss: 0.1259
09/16 01:32:42 PM: Update 20117: task edges-ner-ontonotes, batch 117 (20117): mcc: 0.4968, acc: 0.3326, precision: 0.7686, recall: 0.3436, f1: 0.4749, edges-ner-ontonotes_loss: 0.1241
09/16 01:32:52 PM: Update 20203: task edges-ner-ontonotes, batch 203 (20203): mcc: 0.4971, acc: 0.3349, precision: 0.7645, recall: 0.3460, f1: 0.4764, edges-ner-ontonotes_loss: 0.1251
09/16 01:33:02 PM: Update 20236: task edges-ner-ontonotes, batch 236 (20236): mcc: 0.4939, acc: 0.3325, precision: 0.7596, recall: 0.3441, f1: 0.4737, edges-ner-ontonotes_loss: 0.1256
09/16 01:33:12 PM: Update 20320: task edges-ner-ontonotes, batch 320 (20320): mcc: 0.4974, acc: 0.3350, precision: 0.7615, recall: 0.3481, f1: 0.4777, edges-ner-ontonotes_loss: 0.1226
09/16 01:33:22 PM: Update 20389: task edges-ner-ontonotes, batch 389 (20389): mcc: 0.5007, acc: 0.3370, precision: 0.7654, recall: 0.3505, f1: 0.4808, edges-ner-ontonotes_loss: 0.1213
09/16 01:33:32 PM: Update 20466: task edges-ner-ontonotes, batch 466 (20466): mcc: 0.5047, acc: 0.3406, precision: 0.7695, recall: 0.3538, f1: 0.4848, edges-ner-ontonotes_loss: 0.1201
09/16 01:33:42 PM: Update 20538: task edges-ner-ontonotes, batch 538 (20538): mcc: 0.5066, acc: 0.3423, precision: 0.7714, recall: 0.3555, f1: 0.4867, edges-ner-ontonotes_loss: 0.1193
09/16 01:33:52 PM: Update 20579: task edges-ner-ontonotes, batch 579 (20579): mcc: 0.5060, acc: 0.3422, precision: 0.7701, recall: 0.3554, f1: 0.4864, edges-ner-ontonotes_loss: 0.1191
09/16 01:34:02 PM: Update 20648: task edges-ner-ontonotes, batch 648 (20648): mcc: 0.5081, acc: 0.3446, precision: 0.7710, recall: 0.3578, f1: 0.4888, edges-ner-ontonotes_loss: 0.1185
09/16 01:34:13 PM: Update 20713: task edges-ner-ontonotes, batch 713 (20713): mcc: 0.5094, acc: 0.3459, precision: 0.7722, recall: 0.3590, f1: 0.4902, edges-ner-ontonotes_loss: 0.1183
09/16 01:34:23 PM: Update 20778: task edges-ner-ontonotes, batch 778 (20778): mcc: 0.5103, acc: 0.3467, precision: 0.7723, recall: 0.3601, f1: 0.4912, edges-ner-ontonotes_loss: 0.1180
09/16 01:34:33 PM: Update 20848: task edges-ner-ontonotes, batch 848 (20848): mcc: 0.5117, acc: 0.3480, precision: 0.7738, recall: 0.3613, f1: 0.4926, edges-ner-ontonotes_loss: 0.1177
09/16 01:34:43 PM: Update 20879: task edges-ner-ontonotes, batch 879 (20879): mcc: 0.5111, acc: 0.3476, precision: 0.7726, recall: 0.3610, f1: 0.4921, edges-ner-ontonotes_loss: 0.1176
09/16 01:34:53 PM: Update 20940: task edges-ner-ontonotes, batch 940 (20940): mcc: 0.5119, acc: 0.3488, precision: 0.7712, recall: 0.3630, f1: 0.4936, edges-ner-ontonotes_loss: 0.1172
09/16 01:35:03 PM: ***** Step 21000 / Validation 21 *****
09/16 01:35:03 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:35:03 PM: Validating...
09/16 01:35:03 PM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.4270, acc: 0.2806, precision: 0.7068, recall: 0.2806, f1: 0.4017, edges-ner-ontonotes_loss: 0.1605
09/16 01:35:13 PM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.4855, acc: 0.2996, precision: 0.8182, recall: 0.3066, f1: 0.4461, edges-ner-ontonotes_loss: 0.1213
09/16 01:35:23 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.5361, acc: 0.3439, precision: 0.8564, recall: 0.3542, f1: 0.5011, edges-ner-ontonotes_loss: 0.1146
09/16 01:35:29 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:35:29 PM: Best result seen so far for macro.
09/16 01:35:29 PM: Updating LR scheduler:
09/16 01:35:29 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:35:29 PM: 	# validation passes without improvement: 3
09/16 01:35:29 PM: edges-ner-ontonotes_loss: training: 0.116991 validation: 0.111642
09/16 01:35:29 PM: macro_avg: validation: 0.508879
09/16 01:35:29 PM: micro_avg: validation: 0.000000
09/16 01:35:29 PM: edges-ner-ontonotes_mcc: training: 0.511118 validation: 0.543727
09/16 01:35:29 PM: edges-ner-ontonotes_acc: training: 0.348067 validation: 0.349636
09/16 01:35:29 PM: edges-ner-ontonotes_precision: training: 0.769307 validation: 0.863653
09/16 01:35:29 PM: edges-ner-ontonotes_recall: training: 0.362823 validation: 0.360707
09/16 01:35:29 PM: edges-ner-ontonotes_f1: training: 0.493092 validation: 0.508879
09/16 01:35:29 PM: Global learning rate: 5e-05
09/16 01:35:29 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:35:33 PM: Update 21026: task edges-ner-ontonotes, batch 26 (21026): mcc: 0.5313, acc: 0.3607, precision: 0.7806, recall: 0.3851, f1: 0.5158, edges-ner-ontonotes_loss: 0.1139
09/16 01:35:44 PM: Update 21097: task edges-ner-ontonotes, batch 97 (21097): mcc: 0.5291, acc: 0.3614, precision: 0.7750, recall: 0.3849, f1: 0.5143, edges-ner-ontonotes_loss: 0.1131
09/16 01:35:54 PM: Update 21168: task edges-ner-ontonotes, batch 168 (21168): mcc: 0.5286, acc: 0.3629, precision: 0.7723, recall: 0.3858, f1: 0.5145, edges-ner-ontonotes_loss: 0.1128
09/16 01:36:04 PM: Update 21257: task edges-ner-ontonotes, batch 257 (21257): mcc: 0.5294, acc: 0.3642, precision: 0.7731, recall: 0.3864, f1: 0.5152, edges-ner-ontonotes_loss: 0.1128
09/16 01:36:14 PM: Update 21348: task edges-ner-ontonotes, batch 348 (21348): mcc: 0.5290, acc: 0.3636, precision: 0.7731, recall: 0.3858, f1: 0.5147, edges-ner-ontonotes_loss: 0.1127
09/16 01:36:25 PM: Update 21412: task edges-ner-ontonotes, batch 412 (21412): mcc: 0.5284, acc: 0.3635, precision: 0.7713, recall: 0.3859, f1: 0.5144, edges-ner-ontonotes_loss: 0.1126
09/16 01:36:35 PM: Update 21479: task edges-ner-ontonotes, batch 479 (21479): mcc: 0.5292, acc: 0.3646, precision: 0.7722, recall: 0.3867, f1: 0.5153, edges-ner-ontonotes_loss: 0.1124
09/16 01:36:45 PM: Update 21511: task edges-ner-ontonotes, batch 511 (21511): mcc: 0.5259, acc: 0.3619, precision: 0.7692, recall: 0.3835, f1: 0.5118, edges-ner-ontonotes_loss: 0.1135
09/16 01:36:55 PM: Update 21598: task edges-ner-ontonotes, batch 598 (21598): mcc: 0.5211, acc: 0.3583, precision: 0.7658, recall: 0.3787, f1: 0.5068, edges-ner-ontonotes_loss: 0.1154
09/16 01:37:05 PM: Update 21672: task edges-ner-ontonotes, batch 672 (21672): mcc: 0.5187, acc: 0.3559, precision: 0.7652, recall: 0.3755, f1: 0.5038, edges-ner-ontonotes_loss: 0.1165
09/16 01:37:15 PM: Update 21735: task edges-ner-ontonotes, batch 735 (21735): mcc: 0.5179, acc: 0.3551, precision: 0.7664, recall: 0.3738, f1: 0.5025, edges-ner-ontonotes_loss: 0.1171
09/16 01:37:29 PM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.5162, acc: 0.3536, precision: 0.7656, recall: 0.3718, f1: 0.5006, edges-ner-ontonotes_loss: 0.1176
09/16 01:37:39 PM: Update 21866: task edges-ner-ontonotes, batch 866 (21866): mcc: 0.5153, acc: 0.3524, precision: 0.7662, recall: 0.3703, f1: 0.4993, edges-ner-ontonotes_loss: 0.1175
09/16 01:37:49 PM: Update 21943: task edges-ner-ontonotes, batch 943 (21943): mcc: 0.5146, acc: 0.3516, precision: 0.7662, recall: 0.3693, f1: 0.4984, edges-ner-ontonotes_loss: 0.1174
09/16 01:37:57 PM: ***** Step 22000 / Validation 22 *****
09/16 01:37:57 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:37:57 PM: Validating...
09/16 01:37:59 PM: Evaluate: task edges-ner-ontonotes, batch 8 (157): mcc: 0.5196, acc: 0.3460, precision: 0.8273, recall: 0.3460, f1: 0.4879, edges-ner-ontonotes_loss: 0.1368
09/16 01:38:09 PM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.5449, acc: 0.3435, precision: 0.9060, recall: 0.3438, f1: 0.4985, edges-ner-ontonotes_loss: 0.1106
09/16 01:38:19 PM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.5385, acc: 0.3393, precision: 0.8951, recall: 0.3404, f1: 0.4933, edges-ner-ontonotes_loss: 0.1094
09/16 01:38:23 PM: Updating LR scheduler:
09/16 01:38:23 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:38:23 PM: 	# validation passes without improvement: 0
09/16 01:38:23 PM: edges-ner-ontonotes_loss: training: 0.117156 validation: 0.109547
09/16 01:38:23 PM: macro_avg: validation: 0.489942
09/16 01:38:23 PM: micro_avg: validation: 0.000000
09/16 01:38:23 PM: edges-ner-ontonotes_mcc: training: 0.515141 validation: 0.536279
09/16 01:38:23 PM: edges-ner-ontonotes_acc: training: 0.351980 validation: 0.335836
09/16 01:38:23 PM: edges-ner-ontonotes_precision: training: 0.767264 validation: 0.896712
09/16 01:38:23 PM: edges-ner-ontonotes_recall: training: 0.369482 validation: 0.337049
09/16 01:38:23 PM: edges-ner-ontonotes_f1: training: 0.498774 validation: 0.489942
09/16 01:38:23 PM: Global learning rate: 2.5e-05
09/16 01:38:23 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:38:29 PM: Update 22043: task edges-ner-ontonotes, batch 43 (22043): mcc: 0.5304, acc: 0.3659, precision: 0.7941, recall: 0.3766, f1: 0.5109, edges-ner-ontonotes_loss: 0.1131
09/16 01:38:42 PM: Update 22098: task edges-ner-ontonotes, batch 98 (22098): mcc: 0.5236, acc: 0.3598, precision: 0.7827, recall: 0.3732, f1: 0.5054, edges-ner-ontonotes_loss: 0.1139
09/16 01:38:52 PM: Update 22171: task edges-ner-ontonotes, batch 171 (22171): mcc: 0.5158, acc: 0.3532, precision: 0.7741, recall: 0.3667, f1: 0.4977, edges-ner-ontonotes_loss: 0.1151
09/16 01:39:02 PM: Update 22243: task edges-ner-ontonotes, batch 243 (22243): mcc: 0.5144, acc: 0.3531, precision: 0.7706, recall: 0.3666, f1: 0.4969, edges-ner-ontonotes_loss: 0.1148
09/16 01:39:12 PM: Update 22333: task edges-ner-ontonotes, batch 333 (22333): mcc: 0.5138, acc: 0.3518, precision: 0.7712, recall: 0.3656, f1: 0.4960, edges-ner-ontonotes_loss: 0.1147
09/16 01:39:27 PM: Update 22411: task edges-ner-ontonotes, batch 411 (22411): mcc: 0.5118, acc: 0.3500, precision: 0.7687, recall: 0.3642, f1: 0.4942, edges-ner-ontonotes_loss: 0.1152
09/16 01:39:38 PM: Update 22476: task edges-ner-ontonotes, batch 476 (22476): mcc: 0.5123, acc: 0.3501, precision: 0.7680, recall: 0.3651, f1: 0.4949, edges-ner-ontonotes_loss: 0.1153
09/16 01:39:48 PM: Update 22563: task edges-ner-ontonotes, batch 563 (22563): mcc: 0.5137, acc: 0.3515, precision: 0.7669, recall: 0.3676, f1: 0.4970, edges-ner-ontonotes_loss: 0.1152
09/16 01:39:58 PM: Update 22639: task edges-ner-ontonotes, batch 639 (22639): mcc: 0.5151, acc: 0.3520, precision: 0.7675, recall: 0.3692, f1: 0.4986, edges-ner-ontonotes_loss: 0.1148
09/16 01:40:08 PM: Update 22708: task edges-ner-ontonotes, batch 708 (22708): mcc: 0.5158, acc: 0.3528, precision: 0.7667, recall: 0.3707, f1: 0.4998, edges-ner-ontonotes_loss: 0.1145
09/16 01:40:18 PM: Update 22750: task edges-ner-ontonotes, batch 750 (22750): mcc: 0.5170, acc: 0.3544, precision: 0.7662, recall: 0.3726, f1: 0.5014, edges-ner-ontonotes_loss: 0.1144
09/16 01:40:28 PM: Update 22816: task edges-ner-ontonotes, batch 816 (22816): mcc: 0.5177, acc: 0.3549, precision: 0.7665, recall: 0.3735, f1: 0.5022, edges-ner-ontonotes_loss: 0.1143
09/16 01:40:38 PM: Update 22903: task edges-ner-ontonotes, batch 903 (22903): mcc: 0.5182, acc: 0.3550, precision: 0.7674, recall: 0.3736, f1: 0.5026, edges-ner-ontonotes_loss: 0.1142
09/16 01:40:48 PM: Update 22995: task edges-ner-ontonotes, batch 995 (22995): mcc: 0.5189, acc: 0.3559, precision: 0.7674, recall: 0.3747, f1: 0.5035, edges-ner-ontonotes_loss: 0.1141
09/16 01:40:49 PM: ***** Step 23000 / Validation 23 *****
09/16 01:40:49 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:40:49 PM: Validating...
09/16 01:40:58 PM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.4842, acc: 0.2950, precision: 0.8284, recall: 0.3010, f1: 0.4415, edges-ner-ontonotes_loss: 0.1212
09/16 01:41:10 PM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.5257, acc: 0.3303, precision: 0.8648, recall: 0.3373, f1: 0.4853, edges-ner-ontonotes_loss: 0.1159
09/16 01:41:18 PM: Updating LR scheduler:
09/16 01:41:18 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:41:18 PM: 	# validation passes without improvement: 1
09/16 01:41:18 PM: edges-ner-ontonotes_loss: training: 0.114126 validation: 0.110149
09/16 01:41:18 PM: macro_avg: validation: 0.508662
09/16 01:41:18 PM: micro_avg: validation: 0.000000
09/16 01:41:18 PM: edges-ner-ontonotes_mcc: training: 0.518953 validation: 0.546162
09/16 01:41:18 PM: edges-ner-ontonotes_acc: training: 0.355874 validation: 0.349636
09/16 01:41:18 PM: edges-ner-ontonotes_precision: training: 0.767441 validation: 0.875695
09/16 01:41:18 PM: edges-ner-ontonotes_recall: training: 0.374726 validation: 0.358432
09/16 01:41:18 PM: edges-ner-ontonotes_f1: training: 0.503569 validation: 0.508662
09/16 01:41:18 PM: Global learning rate: 2.5e-05
09/16 01:41:18 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:41:20 PM: Update 23015: task edges-ner-ontonotes, batch 15 (23015): mcc: 0.5314, acc: 0.3628, precision: 0.7739, recall: 0.3888, f1: 0.5176, edges-ner-ontonotes_loss: 0.1128
09/16 01:41:30 PM: Update 23051: task edges-ner-ontonotes, batch 51 (23051): mcc: 0.5162, acc: 0.3557, precision: 0.7547, recall: 0.3777, f1: 0.5035, edges-ner-ontonotes_loss: 0.1172
09/16 01:41:40 PM: Update 23116: task edges-ner-ontonotes, batch 116 (23116): mcc: 0.5013, acc: 0.3407, precision: 0.7538, recall: 0.3573, f1: 0.4848, edges-ner-ontonotes_loss: 0.1232
09/16 01:41:50 PM: Update 23195: task edges-ner-ontonotes, batch 195 (23195): mcc: 0.5016, acc: 0.3409, precision: 0.7589, recall: 0.3551, f1: 0.4838, edges-ner-ontonotes_loss: 0.1235
09/16 01:42:00 PM: Update 23281: task edges-ner-ontonotes, batch 281 (23281): mcc: 0.5042, acc: 0.3427, precision: 0.7629, recall: 0.3566, f1: 0.4860, edges-ner-ontonotes_loss: 0.1234
09/16 01:42:10 PM: Update 23341: task edges-ner-ontonotes, batch 341 (23341): mcc: 0.5003, acc: 0.3388, precision: 0.7593, recall: 0.3530, f1: 0.4820, edges-ner-ontonotes_loss: 0.1240
09/16 01:42:20 PM: Update 23426: task edges-ner-ontonotes, batch 426 (23426): mcc: 0.5027, acc: 0.3401, precision: 0.7628, recall: 0.3546, f1: 0.4841, edges-ner-ontonotes_loss: 0.1221
09/16 01:42:31 PM: Update 23512: task edges-ner-ontonotes, batch 512 (23512): mcc: 0.5057, acc: 0.3431, precision: 0.7656, recall: 0.3573, f1: 0.4872, edges-ner-ontonotes_loss: 0.1209
09/16 01:42:41 PM: Update 23583: task edges-ner-ontonotes, batch 583 (23583): mcc: 0.5078, acc: 0.3452, precision: 0.7677, recall: 0.3590, f1: 0.4893, edges-ner-ontonotes_loss: 0.1201
09/16 01:42:54 PM: Update 23654: task edges-ner-ontonotes, batch 654 (23654): mcc: 0.5094, acc: 0.3461, precision: 0.7698, recall: 0.3602, f1: 0.4908, edges-ner-ontonotes_loss: 0.1194
09/16 01:43:04 PM: Update 23719: task edges-ner-ontonotes, batch 719 (23719): mcc: 0.5094, acc: 0.3460, precision: 0.7698, recall: 0.3602, f1: 0.4907, edges-ner-ontonotes_loss: 0.1190
09/16 01:43:14 PM: Update 23792: task edges-ner-ontonotes, batch 792 (23792): mcc: 0.5088, acc: 0.3456, precision: 0.7690, recall: 0.3598, f1: 0.4902, edges-ner-ontonotes_loss: 0.1188
09/16 01:43:24 PM: Update 23861: task edges-ner-ontonotes, batch 861 (23861): mcc: 0.5082, acc: 0.3454, precision: 0.7679, recall: 0.3595, f1: 0.4898, edges-ner-ontonotes_loss: 0.1186
09/16 01:43:34 PM: Update 23936: task edges-ner-ontonotes, batch 936 (23936): mcc: 0.5094, acc: 0.3464, precision: 0.7689, recall: 0.3607, f1: 0.4911, edges-ner-ontonotes_loss: 0.1182
09/16 01:43:45 PM: Update 23975: task edges-ner-ontonotes, batch 975 (23975): mcc: 0.5103, acc: 0.3474, precision: 0.7691, recall: 0.3618, f1: 0.4921, edges-ner-ontonotes_loss: 0.1180
09/16 01:43:47 PM: ***** Step 24000 / Validation 24 *****
09/16 01:43:47 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:43:47 PM: Validating...
09/16 01:43:55 PM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.5005, acc: 0.3153, precision: 0.8267, recall: 0.3218, f1: 0.4633, edges-ner-ontonotes_loss: 0.1179
09/16 01:44:05 PM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.5330, acc: 0.3402, precision: 0.8605, recall: 0.3483, f1: 0.4959, edges-ner-ontonotes_loss: 0.1136
09/16 01:44:14 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:44:14 PM: Best result seen so far for macro.
09/16 01:44:14 PM: Updating LR scheduler:
09/16 01:44:15 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:44:15 PM: 	# validation passes without improvement: 0
09/16 01:44:15 PM: edges-ner-ontonotes_loss: training: 0.118022 validation: 0.109214
09/16 01:44:15 PM: macro_avg: validation: 0.510964
09/16 01:44:15 PM: micro_avg: validation: 0.000000
09/16 01:44:15 PM: edges-ner-ontonotes_mcc: training: 0.510101 validation: 0.546060
09/16 01:44:15 PM: edges-ner-ontonotes_acc: training: 0.347046 validation: 0.352745
09/16 01:44:15 PM: edges-ner-ontonotes_precision: training: 0.768964 validation: 0.866969
09/16 01:44:15 PM: edges-ner-ontonotes_recall: training: 0.361595 validation: 0.362223
09/16 01:44:15 PM: edges-ner-ontonotes_f1: training: 0.491887 validation: 0.510964
09/16 01:44:15 PM: Global learning rate: 2.5e-05
09/16 01:44:15 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:44:15 PM: Update 24003: task edges-ner-ontonotes, batch 3 (24003): mcc: 0.4767, acc: 0.3145, precision: 0.7016, recall: 0.3508, f1: 0.4677, edges-ner-ontonotes_loss: 0.1272
09/16 01:44:25 PM: Update 24072: task edges-ner-ontonotes, batch 72 (24072): mcc: 0.5271, acc: 0.3624, precision: 0.7691, recall: 0.3853, f1: 0.5134, edges-ner-ontonotes_loss: 0.1130
09/16 01:44:35 PM: Update 24150: task edges-ner-ontonotes, batch 150 (24150): mcc: 0.5291, acc: 0.3638, precision: 0.7710, recall: 0.3872, f1: 0.5155, edges-ner-ontonotes_loss: 0.1121
09/16 01:44:45 PM: Update 24217: task edges-ner-ontonotes, batch 217 (24217): mcc: 0.5286, acc: 0.3648, precision: 0.7692, recall: 0.3874, f1: 0.5153, edges-ner-ontonotes_loss: 0.1122
09/16 01:44:56 PM: Update 24280: task edges-ner-ontonotes, batch 280 (24280): mcc: 0.5281, acc: 0.3634, precision: 0.7696, recall: 0.3865, f1: 0.5145, edges-ner-ontonotes_loss: 0.1123
09/16 01:45:06 PM: Update 24364: task edges-ner-ontonotes, batch 364 (24364): mcc: 0.5284, acc: 0.3640, precision: 0.7686, recall: 0.3875, f1: 0.5152, edges-ner-ontonotes_loss: 0.1124
09/16 01:45:16 PM: Update 24452: task edges-ner-ontonotes, batch 452 (24452): mcc: 0.5278, acc: 0.3640, precision: 0.7681, recall: 0.3869, f1: 0.5146, edges-ner-ontonotes_loss: 0.1123
09/16 01:45:26 PM: Update 24521: task edges-ner-ontonotes, batch 521 (24521): mcc: 0.5287, acc: 0.3648, precision: 0.7689, recall: 0.3878, f1: 0.5156, edges-ner-ontonotes_loss: 0.1121
09/16 01:45:40 PM: Update 24593: task edges-ner-ontonotes, batch 593 (24593): mcc: 0.5276, acc: 0.3636, precision: 0.7688, recall: 0.3862, f1: 0.5142, edges-ner-ontonotes_loss: 0.1124
09/16 01:45:50 PM: Update 24662: task edges-ner-ontonotes, batch 662 (24662): mcc: 0.5241, acc: 0.3602, precision: 0.7673, recall: 0.3820, f1: 0.5101, edges-ner-ontonotes_loss: 0.1139
09/16 01:46:00 PM: Update 24743: task edges-ner-ontonotes, batch 743 (24743): mcc: 0.5208, acc: 0.3571, precision: 0.7662, recall: 0.3780, f1: 0.5062, edges-ner-ontonotes_loss: 0.1152
09/16 01:46:10 PM: Update 24812: task edges-ner-ontonotes, batch 812 (24812): mcc: 0.5190, acc: 0.3557, precision: 0.7654, recall: 0.3758, f1: 0.5041, edges-ner-ontonotes_loss: 0.1160
09/16 01:46:20 PM: Update 24888: task edges-ner-ontonotes, batch 888 (24888): mcc: 0.5164, acc: 0.3536, precision: 0.7641, recall: 0.3730, f1: 0.5013, edges-ner-ontonotes_loss: 0.1169
09/16 01:46:30 PM: Update 24925: task edges-ner-ontonotes, batch 925 (24925): mcc: 0.5157, acc: 0.3528, precision: 0.7638, recall: 0.3722, f1: 0.5005, edges-ner-ontonotes_loss: 0.1170
09/16 01:46:40 PM: ***** Step 25000 / Validation 25 *****
09/16 01:46:40 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:46:40 PM: Validating...
09/16 01:46:40 PM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.5821, acc: 0.4154, precision: 0.8571, recall: 0.4154, f1: 0.5596, edges-ner-ontonotes_loss: 0.1410
09/16 01:46:50 PM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.5367, acc: 0.3351, precision: 0.9002, recall: 0.3362, f1: 0.4896, edges-ner-ontonotes_loss: 0.1105
09/16 01:47:00 PM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.5354, acc: 0.3355, precision: 0.8926, recall: 0.3377, f1: 0.4900, edges-ner-ontonotes_loss: 0.1087
09/16 01:47:05 PM: Updating LR scheduler:
09/16 01:47:05 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:47:05 PM: 	# validation passes without improvement: 1
09/16 01:47:05 PM: edges-ner-ontonotes_loss: training: 0.116861 validation: 0.108558
09/16 01:47:05 PM: macro_avg: validation: 0.487264
09/16 01:47:05 PM: micro_avg: validation: 0.000000
09/16 01:47:05 PM: edges-ner-ontonotes_mcc: training: 0.516299 validation: 0.533354
09/16 01:47:05 PM: edges-ner-ontonotes_acc: training: 0.353102 validation: 0.332575
09/16 01:47:05 PM: edges-ner-ontonotes_precision: training: 0.765404 validation: 0.892727
09/16 01:47:05 PM: edges-ner-ontonotes_recall: training: 0.372090 validation: 0.335077
09/16 01:47:05 PM: edges-ner-ontonotes_f1: training: 0.500748 validation: 0.487264
09/16 01:47:05 PM: Global learning rate: 2.5e-05
09/16 01:47:05 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:47:10 PM: Update 25041: task edges-ner-ontonotes, batch 41 (25041): mcc: 0.5293, acc: 0.3575, precision: 0.8007, recall: 0.3718, f1: 0.5078, edges-ner-ontonotes_loss: 0.1148
09/16 01:47:20 PM: Update 25118: task edges-ner-ontonotes, batch 118 (25118): mcc: 0.5224, acc: 0.3544, precision: 0.7865, recall: 0.3695, f1: 0.5027, edges-ner-ontonotes_loss: 0.1136
09/16 01:47:35 PM: Update 25210: task edges-ner-ontonotes, batch 210 (25210): mcc: 0.5225, acc: 0.3570, precision: 0.7833, recall: 0.3713, f1: 0.5038, edges-ner-ontonotes_loss: 0.1135
09/16 01:47:45 PM: Update 25271: task edges-ner-ontonotes, batch 271 (25271): mcc: 0.5211, acc: 0.3555, precision: 0.7837, recall: 0.3692, f1: 0.5019, edges-ner-ontonotes_loss: 0.1139
09/16 01:47:55 PM: Update 25340: task edges-ner-ontonotes, batch 340 (25340): mcc: 0.5184, acc: 0.3540, precision: 0.7793, recall: 0.3676, f1: 0.4996, edges-ner-ontonotes_loss: 0.1144
09/16 01:48:05 PM: Update 25420: task edges-ner-ontonotes, batch 420 (25420): mcc: 0.5188, acc: 0.3555, precision: 0.7779, recall: 0.3689, f1: 0.5005, edges-ner-ontonotes_loss: 0.1142
09/16 01:48:15 PM: Update 25496: task edges-ner-ontonotes, batch 496 (25496): mcc: 0.5189, acc: 0.3558, precision: 0.7774, recall: 0.3694, f1: 0.5009, edges-ner-ontonotes_loss: 0.1142
09/16 01:48:26 PM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.5190, acc: 0.3561, precision: 0.7769, recall: 0.3698, f1: 0.5011, edges-ner-ontonotes_loss: 0.1143
09/16 01:48:36 PM: Update 25580: task edges-ner-ontonotes, batch 580 (25580): mcc: 0.5180, acc: 0.3549, precision: 0.7759, recall: 0.3690, f1: 0.5001, edges-ner-ontonotes_loss: 0.1144
09/16 01:48:47 PM: Update 25636: task edges-ner-ontonotes, batch 636 (25636): mcc: 0.5186, acc: 0.3558, precision: 0.7742, recall: 0.3707, f1: 0.5014, edges-ner-ontonotes_loss: 0.1143
09/16 01:48:57 PM: Update 25695: task edges-ner-ontonotes, batch 695 (25695): mcc: 0.5200, acc: 0.3568, precision: 0.7744, recall: 0.3725, f1: 0.5030, edges-ner-ontonotes_loss: 0.1141
09/16 01:49:07 PM: Update 25754: task edges-ner-ontonotes, batch 754 (25754): mcc: 0.5202, acc: 0.3572, precision: 0.7730, recall: 0.3735, f1: 0.5036, edges-ner-ontonotes_loss: 0.1140
09/16 01:49:17 PM: Update 25828: task edges-ner-ontonotes, batch 828 (25828): mcc: 0.5225, acc: 0.3593, precision: 0.7738, recall: 0.3763, f1: 0.5063, edges-ner-ontonotes_loss: 0.1136
09/16 01:49:27 PM: Update 25881: task edges-ner-ontonotes, batch 881 (25881): mcc: 0.5226, acc: 0.3596, precision: 0.7732, recall: 0.3767, f1: 0.5066, edges-ner-ontonotes_loss: 0.1136
09/16 01:49:37 PM: Update 25973: task edges-ner-ontonotes, batch 973 (25973): mcc: 0.5231, acc: 0.3599, precision: 0.7731, recall: 0.3775, f1: 0.5073, edges-ner-ontonotes_loss: 0.1135
09/16 01:49:40 PM: ***** Step 26000 / Validation 26 *****
09/16 01:49:40 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:49:40 PM: Validating...
09/16 01:49:47 PM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.4874, acc: 0.3020, precision: 0.8228, recall: 0.3071, f1: 0.4473, edges-ner-ontonotes_loss: 0.1228
09/16 01:49:57 PM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.5272, acc: 0.3321, precision: 0.8646, recall: 0.3392, f1: 0.4872, edges-ner-ontonotes_loss: 0.1160
09/16 01:50:07 PM: Updating LR scheduler:
09/16 01:50:07 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:50:07 PM: 	# validation passes without improvement: 2
09/16 01:50:07 PM: edges-ner-ontonotes_loss: training: 0.113464 validation: 0.109776
09/16 01:50:07 PM: macro_avg: validation: 0.509713
09/16 01:50:07 PM: micro_avg: validation: 0.000000
09/16 01:50:07 PM: edges-ner-ontonotes_mcc: training: 0.523231 validation: 0.546180
09/16 01:50:07 PM: edges-ner-ontonotes_acc: training: 0.359926 validation: 0.351153
09/16 01:50:07 PM: edges-ner-ontonotes_precision: training: 0.773351 validation: 0.872016
09/16 01:50:07 PM: edges-ner-ontonotes_recall: training: 0.377569 validation: 0.360100
09/16 01:50:07 PM: edges-ner-ontonotes_f1: training: 0.507408 validation: 0.509713
09/16 01:50:07 PM: Global learning rate: 2.5e-05
09/16 01:50:07 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:50:07 PM: Update 26004: task edges-ner-ontonotes, batch 4 (26004): mcc: 0.5517, acc: 0.3904, precision: 0.7844, recall: 0.4120, f1: 0.5403, edges-ner-ontonotes_loss: 0.1048
09/16 01:50:17 PM: Update 26078: task edges-ner-ontonotes, batch 78 (26078): mcc: 0.5343, acc: 0.3690, precision: 0.7680, recall: 0.3962, f1: 0.5228, edges-ner-ontonotes_loss: 0.1116
09/16 01:50:27 PM: Update 26145: task edges-ner-ontonotes, batch 145 (26145): mcc: 0.5282, acc: 0.3602, precision: 0.7726, recall: 0.3850, f1: 0.5139, edges-ner-ontonotes_loss: 0.1125
09/16 01:50:38 PM: Update 26190: task edges-ner-ontonotes, batch 190 (26190): mcc: 0.5167, acc: 0.3512, precision: 0.7626, recall: 0.3742, f1: 0.5020, edges-ner-ontonotes_loss: 0.1160
09/16 01:50:48 PM: Update 26280: task edges-ner-ontonotes, batch 280 (26280): mcc: 0.5076, acc: 0.3442, precision: 0.7581, recall: 0.3638, f1: 0.4916, edges-ner-ontonotes_loss: 0.1195
09/16 01:50:58 PM: Update 26349: task edges-ner-ontonotes, batch 349 (26349): mcc: 0.5059, acc: 0.3431, precision: 0.7586, recall: 0.3612, f1: 0.4894, edges-ner-ontonotes_loss: 0.1206
09/16 01:51:08 PM: Update 26434: task edges-ner-ontonotes, batch 434 (26434): mcc: 0.5064, acc: 0.3439, precision: 0.7612, recall: 0.3605, f1: 0.4893, edges-ner-ontonotes_loss: 0.1211
09/16 01:51:18 PM: Update 26487: task edges-ner-ontonotes, batch 487 (26487): mcc: 0.5048, acc: 0.3425, precision: 0.7606, recall: 0.3586, f1: 0.4874, edges-ner-ontonotes_loss: 0.1209
09/16 01:51:28 PM: Update 26585: task edges-ner-ontonotes, batch 585 (26585): mcc: 0.5059, acc: 0.3434, precision: 0.7630, recall: 0.3589, f1: 0.4882, edges-ner-ontonotes_loss: 0.1201
09/16 01:51:38 PM: Update 26666: task edges-ner-ontonotes, batch 666 (26666): mcc: 0.5076, acc: 0.3446, precision: 0.7648, recall: 0.3603, f1: 0.4898, edges-ner-ontonotes_loss: 0.1194
09/16 01:51:48 PM: Update 26755: task edges-ner-ontonotes, batch 755 (26755): mcc: 0.5093, acc: 0.3459, precision: 0.7669, recall: 0.3615, f1: 0.4914, edges-ner-ontonotes_loss: 0.1185
09/16 01:51:58 PM: Update 26801: task edges-ner-ontonotes, batch 801 (26801): mcc: 0.5088, acc: 0.3455, precision: 0.7665, recall: 0.3610, f1: 0.4909, edges-ner-ontonotes_loss: 0.1184
09/16 01:52:08 PM: Update 26862: task edges-ner-ontonotes, batch 862 (26862): mcc: 0.5097, acc: 0.3466, precision: 0.7672, recall: 0.3620, f1: 0.4919, edges-ner-ontonotes_loss: 0.1181
09/16 01:52:18 PM: Update 26933: task edges-ner-ontonotes, batch 933 (26933): mcc: 0.5105, acc: 0.3473, precision: 0.7676, recall: 0.3628, f1: 0.4927, edges-ner-ontonotes_loss: 0.1178
09/16 01:52:29 PM: Update 26997: task edges-ner-ontonotes, batch 997 (26997): mcc: 0.5110, acc: 0.3478, precision: 0.7683, recall: 0.3632, f1: 0.4932, edges-ner-ontonotes_loss: 0.1176
09/16 01:52:29 PM: ***** Step 27000 / Validation 27 *****
09/16 01:52:29 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:52:29 PM: Validating...
09/16 01:52:39 PM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.5436, acc: 0.3423, precision: 0.9037, recall: 0.3432, f1: 0.4975, edges-ner-ontonotes_loss: 0.1087
09/16 01:52:49 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.5422, acc: 0.3429, precision: 0.8943, recall: 0.3454, f1: 0.4983, edges-ner-ontonotes_loss: 0.1090
09/16 01:52:57 PM: Updating LR scheduler:
09/16 01:52:57 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:52:57 PM: 	# validation passes without improvement: 3
09/16 01:52:57 PM: edges-ner-ontonotes_loss: training: 0.117545 validation: 0.107563
09/16 01:52:57 PM: macro_avg: validation: 0.499288
09/16 01:52:57 PM: micro_avg: validation: 0.000000
09/16 01:52:57 PM: edges-ner-ontonotes_mcc: training: 0.511143 validation: 0.543974
09/16 01:52:57 PM: edges-ner-ontonotes_acc: training: 0.347890 validation: 0.342812
09/16 01:52:57 PM: edges-ner-ontonotes_precision: training: 0.768381 validation: 0.899014
09/16 01:52:57 PM: edges-ner-ontonotes_recall: training: 0.363338 validation: 0.345617
09/16 01:52:57 PM: edges-ner-ontonotes_f1: training: 0.493377 validation: 0.499288
09/16 01:52:57 PM: Global learning rate: 2.5e-05
09/16 01:52:57 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:52:59 PM: Update 27016: task edges-ner-ontonotes, batch 16 (27016): mcc: 0.5146, acc: 0.3561, precision: 0.7658, recall: 0.3694, f1: 0.4984, edges-ner-ontonotes_loss: 0.1184
09/16 01:53:14 PM: Update 27079: task edges-ner-ontonotes, batch 79 (27079): mcc: 0.5192, acc: 0.3613, precision: 0.7668, recall: 0.3754, f1: 0.5041, edges-ner-ontonotes_loss: 0.1155
09/16 01:53:24 PM: Update 27154: task edges-ner-ontonotes, batch 154 (27154): mcc: 0.5209, acc: 0.3620, precision: 0.7658, recall: 0.3784, f1: 0.5065, edges-ner-ontonotes_loss: 0.1142
09/16 01:53:34 PM: Update 27221: task edges-ner-ontonotes, batch 221 (27221): mcc: 0.5224, acc: 0.3625, precision: 0.7664, recall: 0.3802, f1: 0.5082, edges-ner-ontonotes_loss: 0.1137
09/16 01:53:44 PM: Update 27301: task edges-ner-ontonotes, batch 301 (27301): mcc: 0.5257, acc: 0.3646, precision: 0.7686, recall: 0.3836, f1: 0.5118, edges-ner-ontonotes_loss: 0.1132
09/16 01:53:54 PM: Update 27374: task edges-ner-ontonotes, batch 374 (27374): mcc: 0.5278, acc: 0.3655, precision: 0.7696, recall: 0.3860, f1: 0.5141, edges-ner-ontonotes_loss: 0.1130
09/16 01:54:04 PM: Update 27405: task edges-ner-ontonotes, batch 405 (27405): mcc: 0.5267, acc: 0.3649, precision: 0.7673, recall: 0.3858, f1: 0.5134, edges-ner-ontonotes_loss: 0.1130
09/16 01:54:14 PM: Update 27491: task edges-ner-ontonotes, batch 491 (27491): mcc: 0.5279, acc: 0.3659, precision: 0.7687, recall: 0.3867, f1: 0.5146, edges-ner-ontonotes_loss: 0.1129
09/16 01:54:24 PM: Update 27580: task edges-ner-ontonotes, batch 580 (27580): mcc: 0.5280, acc: 0.3658, precision: 0.7682, recall: 0.3872, f1: 0.5149, edges-ner-ontonotes_loss: 0.1128
09/16 01:54:35 PM: Update 27635: task edges-ner-ontonotes, batch 635 (27635): mcc: 0.5273, acc: 0.3653, precision: 0.7672, recall: 0.3867, f1: 0.5142, edges-ner-ontonotes_loss: 0.1128
09/16 01:54:50 PM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.5262, acc: 0.3644, precision: 0.7653, recall: 0.3861, f1: 0.5133, edges-ner-ontonotes_loss: 0.1130
09/16 01:55:00 PM: Update 27771: task edges-ner-ontonotes, batch 771 (27771): mcc: 0.5235, acc: 0.3615, precision: 0.7650, recall: 0.3824, f1: 0.5099, edges-ner-ontonotes_loss: 0.1139
09/16 01:55:10 PM: Update 27849: task edges-ner-ontonotes, batch 849 (27849): mcc: 0.5214, acc: 0.3595, precision: 0.7645, recall: 0.3798, f1: 0.5075, edges-ner-ontonotes_loss: 0.1151
09/16 01:55:20 PM: Update 27922: task edges-ner-ontonotes, batch 922 (27922): mcc: 0.5195, acc: 0.3573, precision: 0.7642, recall: 0.3772, f1: 0.5051, edges-ner-ontonotes_loss: 0.1160
09/16 01:55:30 PM: Update 27983: task edges-ner-ontonotes, batch 983 (27983): mcc: 0.5184, acc: 0.3561, precision: 0.7640, recall: 0.3758, f1: 0.5038, edges-ner-ontonotes_loss: 0.1167
09/16 01:55:33 PM: ***** Step 28000 / Validation 28 *****
09/16 01:55:33 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:55:33 PM: Validating...
09/16 01:55:41 PM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.5236, acc: 0.3179, precision: 0.9040, recall: 0.3188, f1: 0.4714, edges-ner-ontonotes_loss: 0.1130
09/16 01:55:51 PM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.5298, acc: 0.3203, precision: 0.9136, recall: 0.3225, f1: 0.4767, edges-ner-ontonotes_loss: 0.1117
09/16 01:56:01 PM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.5350, acc: 0.3277, precision: 0.9077, recall: 0.3311, f1: 0.4852, edges-ner-ontonotes_loss: 0.1084
09/16 01:56:02 PM: Updating LR scheduler:
09/16 01:56:03 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:56:03 PM: 	# validation passes without improvement: 0
09/16 01:56:03 PM: edges-ner-ontonotes_loss: training: 0.116839 validation: 0.108244
09/16 01:56:03 PM: macro_avg: validation: 0.486252
09/16 01:56:03 PM: micro_avg: validation: 0.000000
09/16 01:56:03 PM: edges-ner-ontonotes_mcc: training: 0.518052 validation: 0.536121
09/16 01:56:03 PM: edges-ner-ontonotes_acc: training: 0.355961 validation: 0.328556
09/16 01:56:03 PM: edges-ner-ontonotes_precision: training: 0.763545 validation: 0.909034
09/16 01:56:03 PM: edges-ner-ontonotes_recall: training: 0.375553 validation: 0.331893
09/16 01:56:03 PM: edges-ner-ontonotes_f1: training: 0.503471 validation: 0.486252
09/16 01:56:03 PM: Global learning rate: 1.25e-05
09/16 01:56:03 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:56:12 PM: Update 28009: task edges-ner-ontonotes, batch 9 (28009): mcc: 0.5282, acc: 0.3694, precision: 0.7756, recall: 0.3834, f1: 0.5132, edges-ner-ontonotes_loss: 0.1199
09/16 01:56:22 PM: Update 28068: task edges-ner-ontonotes, batch 68 (28068): mcc: 0.5117, acc: 0.3439, precision: 0.7774, recall: 0.3595, f1: 0.4916, edges-ner-ontonotes_loss: 0.1166
09/16 01:56:32 PM: Update 28136: task edges-ner-ontonotes, batch 136 (28136): mcc: 0.5178, acc: 0.3495, precision: 0.7861, recall: 0.3634, f1: 0.4970, edges-ner-ontonotes_loss: 0.1161
09/16 01:56:42 PM: Update 28242: task edges-ner-ontonotes, batch 242 (28242): mcc: 0.5187, acc: 0.3515, precision: 0.7848, recall: 0.3652, f1: 0.4985, edges-ner-ontonotes_loss: 0.1154
09/16 01:56:52 PM: Update 28306: task edges-ner-ontonotes, batch 306 (28306): mcc: 0.5198, acc: 0.3523, precision: 0.7858, recall: 0.3662, f1: 0.4996, edges-ner-ontonotes_loss: 0.1147
09/16 01:57:02 PM: Update 28332: task edges-ner-ontonotes, batch 332 (28332): mcc: 0.5201, acc: 0.3526, precision: 0.7866, recall: 0.3663, f1: 0.4998, edges-ner-ontonotes_loss: 0.1147
09/16 01:57:12 PM: Update 28404: task edges-ner-ontonotes, batch 404 (28404): mcc: 0.5205, acc: 0.3535, precision: 0.7857, recall: 0.3673, f1: 0.5005, edges-ner-ontonotes_loss: 0.1144
09/16 01:57:22 PM: Update 28479: task edges-ner-ontonotes, batch 479 (28479): mcc: 0.5183, acc: 0.3521, precision: 0.7833, recall: 0.3655, f1: 0.4985, edges-ner-ontonotes_loss: 0.1147
09/16 01:57:32 PM: Update 28546: task edges-ner-ontonotes, batch 546 (28546): mcc: 0.5167, acc: 0.3514, precision: 0.7803, recall: 0.3648, f1: 0.4972, edges-ner-ontonotes_loss: 0.1150
09/16 01:57:43 PM: Update 28623: task edges-ner-ontonotes, batch 623 (28623): mcc: 0.5165, acc: 0.3514, precision: 0.7799, recall: 0.3648, f1: 0.4971, edges-ner-ontonotes_loss: 0.1149
09/16 01:57:53 PM: Update 28658: task edges-ner-ontonotes, batch 658 (28658): mcc: 0.5147, acc: 0.3502, precision: 0.7771, recall: 0.3637, f1: 0.4955, edges-ner-ontonotes_loss: 0.1150
09/16 01:58:03 PM: Update 28724: task edges-ner-ontonotes, batch 724 (28724): mcc: 0.5158, acc: 0.3510, precision: 0.7776, recall: 0.3650, f1: 0.4968, edges-ner-ontonotes_loss: 0.1147
09/16 01:58:13 PM: Update 28794: task edges-ner-ontonotes, batch 794 (28794): mcc: 0.5168, acc: 0.3522, precision: 0.7760, recall: 0.3673, f1: 0.4986, edges-ner-ontonotes_loss: 0.1146
09/16 01:58:23 PM: Update 28859: task edges-ner-ontonotes, batch 859 (28859): mcc: 0.5181, acc: 0.3533, precision: 0.7761, recall: 0.3689, f1: 0.5001, edges-ner-ontonotes_loss: 0.1143
09/16 01:58:33 PM: Update 28927: task edges-ner-ontonotes, batch 927 (28927): mcc: 0.5194, acc: 0.3549, precision: 0.7755, recall: 0.3711, f1: 0.5020, edges-ner-ontonotes_loss: 0.1140
09/16 01:58:43 PM: Update 28966: task edges-ner-ontonotes, batch 966 (28966): mcc: 0.5202, acc: 0.3558, precision: 0.7750, recall: 0.3725, f1: 0.5031, edges-ner-ontonotes_loss: 0.1138
09/16 01:58:47 PM: ***** Step 29000 / Validation 29 *****
09/16 01:58:47 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:58:47 PM: Validating...
09/16 01:58:53 PM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.4758, acc: 0.2875, precision: 0.8175, recall: 0.2950, f1: 0.4336, edges-ner-ontonotes_loss: 0.1212
09/16 01:59:03 PM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.5269, acc: 0.3310, precision: 0.8610, recall: 0.3404, f1: 0.4879, edges-ner-ontonotes_loss: 0.1146
09/16 01:59:10 PM: Updating LR scheduler:
09/16 01:59:10 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:59:10 PM: 	# validation passes without improvement: 1
09/16 01:59:10 PM: edges-ner-ontonotes_loss: training: 0.113797 validation: 0.110166
09/16 01:59:10 PM: macro_avg: validation: 0.506592
09/16 01:59:10 PM: micro_avg: validation: 0.000000
09/16 01:59:10 PM: edges-ner-ontonotes_mcc: training: 0.519906 validation: 0.543862
09/16 01:59:10 PM: edges-ner-ontonotes_acc: training: 0.355529 validation: 0.347134
09/16 01:59:10 PM: edges-ner-ontonotes_precision: training: 0.774082 validation: 0.872474
09/16 01:59:10 PM: edges-ner-ontonotes_recall: training: 0.372528 validation: 0.356915
09/16 01:59:10 PM: edges-ner-ontonotes_f1: training: 0.502991 validation: 0.506592
09/16 01:59:10 PM: Global learning rate: 1.25e-05
09/16 01:59:10 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 01:59:13 PM: Update 29021: task edges-ner-ontonotes, batch 21 (29021): mcc: 0.5211, acc: 0.3503, precision: 0.7725, recall: 0.3751, f1: 0.5050, edges-ner-ontonotes_loss: 0.1124
09/16 01:59:23 PM: Update 29086: task edges-ner-ontonotes, batch 86 (29086): mcc: 0.5163, acc: 0.3484, precision: 0.7652, recall: 0.3721, f1: 0.5007, edges-ner-ontonotes_loss: 0.1124
09/16 01:59:33 PM: Update 29159: task edges-ner-ontonotes, batch 159 (29159): mcc: 0.5223, acc: 0.3571, precision: 0.7710, recall: 0.3775, f1: 0.5069, edges-ner-ontonotes_loss: 0.1121
09/16 01:59:43 PM: Update 29231: task edges-ner-ontonotes, batch 231 (29231): mcc: 0.5223, acc: 0.3574, precision: 0.7697, recall: 0.3782, f1: 0.5072, edges-ner-ontonotes_loss: 0.1122
09/16 01:59:53 PM: Update 29279: task edges-ner-ontonotes, batch 279 (29279): mcc: 0.5227, acc: 0.3590, precision: 0.7666, recall: 0.3805, f1: 0.5086, edges-ner-ontonotes_loss: 0.1133
09/16 02:00:04 PM: Update 29348: task edges-ner-ontonotes, batch 348 (29348): mcc: 0.5176, acc: 0.3537, precision: 0.7658, recall: 0.3738, f1: 0.5024, edges-ner-ontonotes_loss: 0.1160
09/16 02:00:14 PM: Update 29411: task edges-ner-ontonotes, batch 411 (29411): mcc: 0.5148, acc: 0.3512, precision: 0.7648, recall: 0.3704, f1: 0.4991, edges-ner-ontonotes_loss: 0.1173
09/16 02:00:24 PM: Update 29480: task edges-ner-ontonotes, batch 480 (29480): mcc: 0.5126, acc: 0.3494, precision: 0.7638, recall: 0.3678, f1: 0.4965, edges-ner-ontonotes_loss: 0.1184
09/16 02:00:34 PM: Update 29551: task edges-ner-ontonotes, batch 551 (29551): mcc: 0.5112, acc: 0.3481, precision: 0.7636, recall: 0.3659, f1: 0.4948, edges-ner-ontonotes_loss: 0.1190
09/16 02:00:44 PM: Update 29601: task edges-ner-ontonotes, batch 601 (29601): mcc: 0.5105, acc: 0.3469, precision: 0.7646, recall: 0.3644, f1: 0.4935, edges-ner-ontonotes_loss: 0.1191
09/16 02:00:54 PM: Update 29688: task edges-ner-ontonotes, batch 688 (29688): mcc: 0.5120, acc: 0.3484, precision: 0.7659, recall: 0.3658, f1: 0.4951, edges-ner-ontonotes_loss: 0.1185
09/16 02:01:05 PM: Update 29785: task edges-ner-ontonotes, batch 785 (29785): mcc: 0.5124, acc: 0.3488, precision: 0.7669, recall: 0.3658, f1: 0.4953, edges-ner-ontonotes_loss: 0.1180
09/16 02:01:15 PM: Update 29853: task edges-ner-ontonotes, batch 853 (29853): mcc: 0.5142, acc: 0.3502, precision: 0.7694, recall: 0.3670, f1: 0.4970, edges-ner-ontonotes_loss: 0.1177
09/16 02:01:27 PM: Update 29878: task edges-ner-ontonotes, batch 878 (29878): mcc: 0.5134, acc: 0.3495, precision: 0.7690, recall: 0.3662, f1: 0.4961, edges-ner-ontonotes_loss: 0.1178
09/16 02:01:37 PM: Update 29939: task edges-ner-ontonotes, batch 939 (29939): mcc: 0.5133, acc: 0.3493, precision: 0.7696, recall: 0.3657, f1: 0.4958, edges-ner-ontonotes_loss: 0.1177
09/16 02:01:44 PM: ***** Step 30000 / Validation 30 *****
09/16 02:01:44 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:01:44 PM: Validating...
09/16 02:01:47 PM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.5070, acc: 0.3160, precision: 0.8539, recall: 0.3186, f1: 0.4640, edges-ner-ontonotes_loss: 0.1216
09/16 02:01:57 PM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.5460, acc: 0.3433, precision: 0.9048, recall: 0.3457, f1: 0.5003, edges-ner-ontonotes_loss: 0.1095
09/16 02:02:07 PM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.5427, acc: 0.3408, precision: 0.8974, recall: 0.3446, f1: 0.4980, edges-ner-ontonotes_loss: 0.1075
09/16 02:02:10 PM: Updating LR scheduler:
09/16 02:02:10 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:02:10 PM: 	# validation passes without improvement: 2
09/16 02:02:10 PM: edges-ner-ontonotes_loss: training: 0.117542 validation: 0.107473
09/16 02:02:10 PM: macro_avg: validation: 0.495357
09/16 02:02:10 PM: micro_avg: validation: 0.000000
09/16 02:02:10 PM: edges-ner-ontonotes_mcc: training: 0.513470 validation: 0.541000
09/16 02:02:10 PM: edges-ner-ontonotes_acc: training: 0.349616 validation: 0.337959
09/16 02:02:10 PM: edges-ner-ontonotes_precision: training: 0.769591 validation: 0.899262
09/16 02:02:10 PM: edges-ner-ontonotes_recall: training: 0.365932 validation: 0.341826
09/16 02:02:10 PM: edges-ner-ontonotes_f1: training: 0.496014 validation: 0.495357
09/16 02:02:10 PM: Global learning rate: 1.25e-05
09/16 02:02:10 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:02:17 PM: Update 30065: task edges-ner-ontonotes, batch 65 (30065): mcc: 0.5096, acc: 0.3478, precision: 0.7706, recall: 0.3601, f1: 0.4908, edges-ner-ontonotes_loss: 0.1160
09/16 02:02:27 PM: Update 30148: task edges-ner-ontonotes, batch 148 (30148): mcc: 0.5099, acc: 0.3481, precision: 0.7672, recall: 0.3622, f1: 0.4921, edges-ner-ontonotes_loss: 0.1153
09/16 02:02:38 PM: Update 30192: task edges-ner-ontonotes, batch 192 (30192): mcc: 0.5082, acc: 0.3473, precision: 0.7629, recall: 0.3621, f1: 0.4911, edges-ner-ontonotes_loss: 0.1157
09/16 02:02:48 PM: Update 30267: task edges-ner-ontonotes, batch 267 (30267): mcc: 0.5080, acc: 0.3464, precision: 0.7621, recall: 0.3622, f1: 0.4910, edges-ner-ontonotes_loss: 0.1156
09/16 02:02:58 PM: Update 30336: task edges-ner-ontonotes, batch 336 (30336): mcc: 0.5139, acc: 0.3526, precision: 0.7635, recall: 0.3698, f1: 0.4982, edges-ner-ontonotes_loss: 0.1147
09/16 02:03:08 PM: Update 30410: task edges-ner-ontonotes, batch 410 (30410): mcc: 0.5181, acc: 0.3560, precision: 0.7659, recall: 0.3743, f1: 0.5029, edges-ner-ontonotes_loss: 0.1139
09/16 02:03:18 PM: Update 30499: task edges-ner-ontonotes, batch 499 (30499): mcc: 0.5206, acc: 0.3580, precision: 0.7673, recall: 0.3771, f1: 0.5057, edges-ner-ontonotes_loss: 0.1137
09/16 02:03:28 PM: Update 30535: task edges-ner-ontonotes, batch 535 (30535): mcc: 0.5205, acc: 0.3580, precision: 0.7662, recall: 0.3776, f1: 0.5059, edges-ner-ontonotes_loss: 0.1138
09/16 02:03:38 PM: Update 30602: task edges-ner-ontonotes, batch 602 (30602): mcc: 0.5215, acc: 0.3591, precision: 0.7668, recall: 0.3787, f1: 0.5070, edges-ner-ontonotes_loss: 0.1135
09/16 02:03:48 PM: Update 30660: task edges-ner-ontonotes, batch 660 (30660): mcc: 0.5215, acc: 0.3589, precision: 0.7664, recall: 0.3788, f1: 0.5070, edges-ner-ontonotes_loss: 0.1135
09/16 02:03:58 PM: Update 30758: task edges-ner-ontonotes, batch 758 (30758): mcc: 0.5222, acc: 0.3591, precision: 0.7674, recall: 0.3793, f1: 0.5076, edges-ner-ontonotes_loss: 0.1134
09/16 02:04:09 PM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.5231, acc: 0.3597, precision: 0.7679, recall: 0.3803, f1: 0.5086, edges-ner-ontonotes_loss: 0.1133
09/16 02:04:19 PM: Update 30878: task edges-ner-ontonotes, batch 878 (30878): mcc: 0.5207, acc: 0.3578, precision: 0.7667, recall: 0.3776, f1: 0.5060, edges-ner-ontonotes_loss: 0.1142
09/16 02:04:29 PM: Update 30959: task edges-ner-ontonotes, batch 959 (30959): mcc: 0.5189, acc: 0.3558, precision: 0.7664, recall: 0.3752, f1: 0.5038, edges-ner-ontonotes_loss: 0.1151
09/16 02:04:34 PM: ***** Step 31000 / Validation 31 *****
09/16 02:04:34 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:04:34 PM: Validating...
09/16 02:04:39 PM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.5285, acc: 0.3263, precision: 0.8967, recall: 0.3275, f1: 0.4798, edges-ner-ontonotes_loss: 0.1146
09/16 02:04:49 PM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.5403, acc: 0.3328, precision: 0.9131, recall: 0.3354, f1: 0.4905, edges-ner-ontonotes_loss: 0.1097
09/16 02:04:59 PM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.5424, acc: 0.3356, precision: 0.9073, recall: 0.3402, f1: 0.4949, edges-ner-ontonotes_loss: 0.1074
09/16 02:05:00 PM: Updating LR scheduler:
09/16 02:05:00 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:05:00 PM: 	# validation passes without improvement: 3
09/16 02:05:00 PM: edges-ner-ontonotes_loss: training: 0.115469 validation: 0.107191
09/16 02:05:00 PM: macro_avg: validation: 0.496638
09/16 02:05:00 PM: micro_avg: validation: 0.000000
09/16 02:05:00 PM: edges-ner-ontonotes_mcc: training: 0.518282 validation: 0.544064
09/16 02:05:00 PM: edges-ner-ontonotes_acc: training: 0.355148 validation: 0.337200
09/16 02:05:00 PM: edges-ner-ontonotes_precision: training: 0.766529 validation: 0.908834
09/16 02:05:00 PM: edges-ner-ontonotes_recall: training: 0.374273 validation: 0.341674
09/16 02:05:00 PM: edges-ner-ontonotes_f1: training: 0.502963 validation: 0.496638
09/16 02:05:00 PM: Global learning rate: 1.25e-05
09/16 02:05:00 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:05:09 PM: Update 31074: task edges-ner-ontonotes, batch 74 (31074): mcc: 0.4986, acc: 0.3405, precision: 0.7518, recall: 0.3546, f1: 0.4819, edges-ner-ontonotes_loss: 0.1258
09/16 02:05:19 PM: Update 31127: task edges-ner-ontonotes, batch 127 (31127): mcc: 0.4948, acc: 0.3372, precision: 0.7492, recall: 0.3507, f1: 0.4778, edges-ner-ontonotes_loss: 0.1262
09/16 02:05:30 PM: Update 31217: task edges-ner-ontonotes, batch 217 (31217): mcc: 0.4957, acc: 0.3367, precision: 0.7530, recall: 0.3499, f1: 0.4778, edges-ner-ontonotes_loss: 0.1221
09/16 02:05:40 PM: Update 31305: task edges-ner-ontonotes, batch 305 (31305): mcc: 0.5034, acc: 0.3419, precision: 0.7631, recall: 0.3554, f1: 0.4850, edges-ner-ontonotes_loss: 0.1201
09/16 02:05:50 PM: Update 31383: task edges-ner-ontonotes, batch 383 (31383): mcc: 0.5082, acc: 0.3452, precision: 0.7689, recall: 0.3590, f1: 0.4895, edges-ner-ontonotes_loss: 0.1185
09/16 02:06:00 PM: Update 31434: task edges-ner-ontonotes, batch 434 (31434): mcc: 0.5081, acc: 0.3451, precision: 0.7683, recall: 0.3592, f1: 0.4895, edges-ner-ontonotes_loss: 0.1181
09/16 02:06:10 PM: Update 31509: task edges-ner-ontonotes, batch 509 (31509): mcc: 0.5101, acc: 0.3467, precision: 0.7706, recall: 0.3608, f1: 0.4915, edges-ner-ontonotes_loss: 0.1178
09/16 02:06:20 PM: Update 31585: task edges-ner-ontonotes, batch 585 (31585): mcc: 0.5107, acc: 0.3478, precision: 0.7696, recall: 0.3620, f1: 0.4924, edges-ner-ontonotes_loss: 0.1174
09/16 02:06:31 PM: Update 31656: task edges-ner-ontonotes, batch 656 (31656): mcc: 0.5121, acc: 0.3492, precision: 0.7707, recall: 0.3634, f1: 0.4939, edges-ner-ontonotes_loss: 0.1171
09/16 02:06:41 PM: Update 31734: task edges-ner-ontonotes, batch 734 (31734): mcc: 0.5129, acc: 0.3503, precision: 0.7706, recall: 0.3646, f1: 0.4950, edges-ner-ontonotes_loss: 0.1168
09/16 02:06:51 PM: Update 31758: task edges-ner-ontonotes, batch 758 (31758): mcc: 0.5126, acc: 0.3499, precision: 0.7707, recall: 0.3642, f1: 0.4946, edges-ner-ontonotes_loss: 0.1168
09/16 02:07:01 PM: Update 31827: task edges-ner-ontonotes, batch 827 (31827): mcc: 0.5118, acc: 0.3495, precision: 0.7685, recall: 0.3642, f1: 0.4942, edges-ner-ontonotes_loss: 0.1167
09/16 02:07:11 PM: Update 31902: task edges-ner-ontonotes, batch 902 (31902): mcc: 0.5143, acc: 0.3515, precision: 0.7699, recall: 0.3669, f1: 0.4970, edges-ner-ontonotes_loss: 0.1162
09/16 02:07:21 PM: Update 31968: task edges-ner-ontonotes, batch 968 (31968): mcc: 0.5160, acc: 0.3530, precision: 0.7706, recall: 0.3689, f1: 0.4990, edges-ner-ontonotes_loss: 0.1157
09/16 02:07:27 PM: ***** Step 32000 / Validation 32 *****
09/16 02:07:27 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:07:27 PM: Validating...
09/16 02:07:31 PM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.4466, acc: 0.2751, precision: 0.7695, recall: 0.2787, f1: 0.4092, edges-ner-ontonotes_loss: 0.1332
09/16 02:07:42 PM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.5156, acc: 0.3237, precision: 0.8481, recall: 0.3317, f1: 0.4768, edges-ner-ontonotes_loss: 0.1171
09/16 02:07:51 PM: Updating LR scheduler:
09/16 02:07:51 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:07:51 PM: 	# validation passes without improvement: 0
09/16 02:07:51 PM: edges-ner-ontonotes_loss: training: 0.115670 validation: 0.110335
09/16 02:07:51 PM: macro_avg: validation: 0.510249
09/16 02:07:51 PM: micro_avg: validation: 0.000000
09/16 02:07:51 PM: edges-ner-ontonotes_mcc: training: 0.516500 validation: 0.545555
09/16 02:07:51 PM: edges-ner-ontonotes_acc: training: 0.353621 validation: 0.351228
09/16 02:07:51 PM: edges-ner-ontonotes_precision: training: 0.770390 validation: 0.867200
09/16 02:07:51 PM: edges-ner-ontonotes_recall: training: 0.369727 validation: 0.361465
09/16 02:07:51 PM: edges-ner-ontonotes_f1: training: 0.499657 validation: 0.510249
09/16 02:07:51 PM: Global learning rate: 6.25e-06
09/16 02:07:51 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:07:52 PM: Update 32004: task edges-ner-ontonotes, batch 4 (32004): mcc: 0.5886, acc: 0.4227, precision: 0.7981, recall: 0.4586, f1: 0.5825, edges-ner-ontonotes_loss: 0.1055
09/16 02:08:02 PM: Update 32087: task edges-ner-ontonotes, batch 87 (32087): mcc: 0.5329, acc: 0.3706, precision: 0.7712, recall: 0.3924, f1: 0.5202, edges-ner-ontonotes_loss: 0.1137
09/16 02:08:12 PM: Update 32174: task edges-ner-ontonotes, batch 174 (32174): mcc: 0.5287, acc: 0.3649, precision: 0.7696, recall: 0.3873, f1: 0.5153, edges-ner-ontonotes_loss: 0.1138
09/16 02:08:22 PM: Update 32261: task edges-ner-ontonotes, batch 261 (32261): mcc: 0.5281, acc: 0.3638, precision: 0.7697, recall: 0.3865, f1: 0.5146, edges-ner-ontonotes_loss: 0.1129
09/16 02:08:32 PM: Update 32329: task edges-ner-ontonotes, batch 329 (32329): mcc: 0.5273, acc: 0.3632, precision: 0.7694, recall: 0.3854, f1: 0.5136, edges-ner-ontonotes_loss: 0.1129
09/16 02:08:45 PM: Update 32373: task edges-ner-ontonotes, batch 373 (32373): mcc: 0.5279, acc: 0.3641, precision: 0.7686, recall: 0.3868, f1: 0.5146, edges-ner-ontonotes_loss: 0.1129
09/16 02:08:55 PM: Update 32438: task edges-ner-ontonotes, batch 438 (32438): mcc: 0.5237, acc: 0.3601, precision: 0.7669, recall: 0.3817, f1: 0.5097, edges-ner-ontonotes_loss: 0.1150
09/16 02:09:05 PM: Update 32518: task edges-ner-ontonotes, batch 518 (32518): mcc: 0.5204, acc: 0.3566, precision: 0.7666, recall: 0.3773, f1: 0.5057, edges-ner-ontonotes_loss: 0.1164
09/16 02:09:15 PM: Update 32595: task edges-ner-ontonotes, batch 595 (32595): mcc: 0.5176, acc: 0.3541, precision: 0.7658, recall: 0.3737, f1: 0.5023, edges-ner-ontonotes_loss: 0.1178
09/16 02:09:25 PM: Update 32671: task edges-ner-ontonotes, batch 671 (32671): mcc: 0.5148, acc: 0.3516, precision: 0.7651, recall: 0.3701, f1: 0.4989, edges-ner-ontonotes_loss: 0.1186
09/16 02:09:35 PM: Update 32711: task edges-ner-ontonotes, batch 711 (32711): mcc: 0.5144, acc: 0.3512, precision: 0.7651, recall: 0.3695, f1: 0.4984, edges-ner-ontonotes_loss: 0.1185
09/16 02:09:45 PM: Update 32803: task edges-ner-ontonotes, batch 803 (32803): mcc: 0.5148, acc: 0.3512, precision: 0.7668, recall: 0.3692, f1: 0.4985, edges-ner-ontonotes_loss: 0.1180
09/16 02:09:55 PM: Update 32864: task edges-ner-ontonotes, batch 864 (32864): mcc: 0.5151, acc: 0.3514, precision: 0.7680, recall: 0.3691, f1: 0.4986, edges-ner-ontonotes_loss: 0.1177
09/16 02:10:05 PM: Update 32944: task edges-ner-ontonotes, batch 944 (32944): mcc: 0.5153, acc: 0.3514, precision: 0.7689, recall: 0.3688, f1: 0.4985, edges-ner-ontonotes_loss: 0.1175
09/16 02:10:18 PM: Update 32990: task edges-ner-ontonotes, batch 990 (32990): mcc: 0.5155, acc: 0.3517, precision: 0.7691, recall: 0.3689, f1: 0.4987, edges-ner-ontonotes_loss: 0.1173
09/16 02:10:20 PM: ***** Step 33000 / Validation 33 *****
09/16 02:10:20 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:10:20 PM: Validating...
09/16 02:10:28 PM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.5372, acc: 0.3351, precision: 0.9030, recall: 0.3357, f1: 0.4894, edges-ner-ontonotes_loss: 0.1112
09/16 02:10:39 PM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.5369, acc: 0.3350, precision: 0.8996, recall: 0.3367, f1: 0.4900, edges-ner-ontonotes_loss: 0.1107
09/16 02:10:49 PM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.5371, acc: 0.3361, precision: 0.8946, recall: 0.3389, f1: 0.4916, edges-ner-ontonotes_loss: 0.1082
09/16 02:10:49 PM: Updating LR scheduler:
09/16 02:10:49 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:10:49 PM: 	# validation passes without improvement: 1
09/16 02:10:49 PM: edges-ner-ontonotes_loss: training: 0.117327 validation: 0.108065
09/16 02:10:49 PM: macro_avg: validation: 0.491253
09/16 02:10:49 PM: micro_avg: validation: 0.000000
09/16 02:10:49 PM: edges-ner-ontonotes_mcc: training: 0.515072 validation: 0.536870
09/16 02:10:49 PM: edges-ner-ontonotes_acc: training: 0.351428 validation: 0.335760
09/16 02:10:49 PM: edges-ner-ontonotes_precision: training: 0.768719 validation: 0.894790
09/16 02:10:49 PM: edges-ner-ontonotes_recall: training: 0.368616 validation: 0.338565
09/16 02:10:49 PM: edges-ner-ontonotes_f1: training: 0.498292 validation: 0.491253
09/16 02:10:49 PM: Global learning rate: 6.25e-06
09/16 02:10:49 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:10:59 PM: Update 33064: task edges-ner-ontonotes, batch 64 (33064): mcc: 0.5129, acc: 0.3488, precision: 0.7822, recall: 0.3587, f1: 0.4919, edges-ner-ontonotes_loss: 0.1162
09/16 02:11:09 PM: Update 33141: task edges-ner-ontonotes, batch 141 (33141): mcc: 0.5192, acc: 0.3550, precision: 0.7839, recall: 0.3665, f1: 0.4995, edges-ner-ontonotes_loss: 0.1152
09/16 02:11:19 PM: Update 33200: task edges-ner-ontonotes, batch 200 (33200): mcc: 0.5156, acc: 0.3511, precision: 0.7793, recall: 0.3639, f1: 0.4961, edges-ner-ontonotes_loss: 0.1149
09/16 02:11:29 PM: Update 33271: task edges-ner-ontonotes, batch 271 (33271): mcc: 0.5162, acc: 0.3512, precision: 0.7801, recall: 0.3642, f1: 0.4966, edges-ner-ontonotes_loss: 0.1146
09/16 02:11:39 PM: Update 33305: task edges-ner-ontonotes, batch 305 (33305): mcc: 0.5145, acc: 0.3497, precision: 0.7783, recall: 0.3629, f1: 0.4950, edges-ner-ontonotes_loss: 0.1148
09/16 02:11:49 PM: Update 33389: task edges-ner-ontonotes, batch 389 (33389): mcc: 0.5137, acc: 0.3485, precision: 0.7764, recall: 0.3627, f1: 0.4945, edges-ner-ontonotes_loss: 0.1147
09/16 02:12:00 PM: Update 33454: task edges-ner-ontonotes, batch 454 (33454): mcc: 0.5144, acc: 0.3494, precision: 0.7748, recall: 0.3645, f1: 0.4958, edges-ner-ontonotes_loss: 0.1145
09/16 02:12:10 PM: Update 33534: task edges-ner-ontonotes, batch 534 (33534): mcc: 0.5164, acc: 0.3516, precision: 0.7737, recall: 0.3679, f1: 0.4987, edges-ner-ontonotes_loss: 0.1141
09/16 02:12:20 PM: Update 33613: task edges-ner-ontonotes, batch 613 (33613): mcc: 0.5197, acc: 0.3553, precision: 0.7736, recall: 0.3725, f1: 0.5028, edges-ner-ontonotes_loss: 0.1137
09/16 02:12:30 PM: Update 33679: task edges-ner-ontonotes, batch 679 (33679): mcc: 0.5194, acc: 0.3553, precision: 0.7721, recall: 0.3729, f1: 0.5029, edges-ner-ontonotes_loss: 0.1138
09/16 02:12:40 PM: Update 33768: task edges-ner-ontonotes, batch 768 (33768): mcc: 0.5210, acc: 0.3570, precision: 0.7723, recall: 0.3749, f1: 0.5048, edges-ner-ontonotes_loss: 0.1133
09/16 02:12:50 PM: Update 33833: task edges-ner-ontonotes, batch 833 (33833): mcc: 0.5212, acc: 0.3569, precision: 0.7719, recall: 0.3755, f1: 0.5053, edges-ner-ontonotes_loss: 0.1133
09/16 02:13:00 PM: Update 33897: task edges-ner-ontonotes, batch 897 (33897): mcc: 0.5212, acc: 0.3571, precision: 0.7705, recall: 0.3762, f1: 0.5056, edges-ner-ontonotes_loss: 0.1133
09/16 02:13:10 PM: Update 33929: task edges-ner-ontonotes, batch 929 (33929): mcc: 0.5210, acc: 0.3571, precision: 0.7701, recall: 0.3762, f1: 0.5055, edges-ner-ontonotes_loss: 0.1133
09/16 02:13:19 PM: ***** Step 34000 / Validation 34 *****
09/16 02:13:19 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:13:19 PM: Validating...
09/16 02:13:20 PM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.4911, acc: 0.3300, precision: 0.7811, recall: 0.3300, f1: 0.4640, edges-ner-ontonotes_loss: 0.1430
09/16 02:13:30 PM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.5140, acc: 0.3082, precision: 0.8932, recall: 0.3115, f1: 0.4619, edges-ner-ontonotes_loss: 0.1139
09/16 02:13:40 PM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.5366, acc: 0.3288, precision: 0.9011, recall: 0.3357, f1: 0.4891, edges-ner-ontonotes_loss: 0.1098
09/16 02:13:46 PM: Updating LR scheduler:
09/16 02:13:46 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:13:46 PM: 	# validation passes without improvement: 2
09/16 02:13:46 PM: Ran out of early stopping patience. Stopping training.
09/16 02:13:46 PM: edges-ner-ontonotes_loss: training: 0.114353 validation: 0.107214
09/16 02:13:46 PM: macro_avg: validation: 0.498901
09/16 02:13:46 PM: micro_avg: validation: 0.000000
09/16 02:13:46 PM: edges-ner-ontonotes_mcc: training: 0.519097 validation: 0.545381
09/16 02:13:46 PM: edges-ner-ontonotes_acc: training: 0.355291 validation: 0.337200
09/16 02:13:46 PM: edges-ner-ontonotes_precision: training: 0.768743 validation: 0.906874
09/16 02:13:46 PM: edges-ner-ontonotes_recall: training: 0.374232 validation: 0.344101
09/16 02:13:46 PM: edges-ner-ontonotes_f1: training: 0.503402 validation: 0.498901
09/16 02:13:46 PM: Global learning rate: 6.25e-06
09/16 02:13:46 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:13:46 PM: Stopped training after 34 validation checks
09/16 02:13:46 PM: Trained edges-ner-ontonotes for 34000 batches or 21.879 epochs
09/16 02:13:46 PM: ***** VALIDATION RESULTS *****
09/16 02:13:46 PM: edges-ner-ontonotes_f1 (for best val pass 24): edges-ner-ontonotes_loss: 0.10921, macro_avg: 0.51096, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.54606, edges-ner-ontonotes_acc: 0.35274, edges-ner-ontonotes_precision: 0.86697, edges-ner-ontonotes_recall: 0.36222, edges-ner-ontonotes_f1: 0.51096
09/16 02:13:46 PM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.14146, macro_avg: 0.31833, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.39107, edges-ner-ontonotes_acc: 0.19594, edges-ner-ontonotes_precision: 0.83152, edges-ner-ontonotes_recall: 0.19685, edges-ner-ontonotes_f1: 0.31833
09/16 02:13:46 PM: macro_avg (for best val pass 24): edges-ner-ontonotes_loss: 0.10921, macro_avg: 0.51096, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.54606, edges-ner-ontonotes_acc: 0.35274, edges-ner-ontonotes_precision: 0.86697, edges-ner-ontonotes_recall: 0.36222, edges-ner-ontonotes_f1: 0.51096
09/16 02:13:46 PM: Evaluating...
09/16 02:13:46 PM: Loaded model state from ./experiments/ner-ontonotes-RANDOM-top/run/edges-ner-ontonotes/model_state_target_train_val_24.best.th
09/16 02:13:46 PM: Evaluating on: edges-ner-ontonotes, split: val
09/16 02:14:16 PM: 	Task edges-ner-ontonotes: batch 166
09/16 02:14:28 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 02:14:28 PM: Finished evaluating on: edges-ner-ontonotes
09/16 02:14:28 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 02:14:30 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:14:30 PM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:14:30 PM: Evaluating on: edges-ner-ontonotes, split: test
09/16 02:14:59 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 02:14:59 PM: Finished evaluating on: edges-ner-ontonotes
09/16 02:14:59 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 02:15:00 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:15:00 PM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-RANDOM-top/run
09/16 02:15:00 PM: Writing results for split 'val' to ./experiments/ner-ontonotes-RANDOM-top/results.tsv
09/16 02:15:00 PM: micro_avg: 0.000, macro_avg: 0.513, edges-ner-ontonotes_mcc: 0.549, edges-ner-ontonotes_acc: 0.354, edges-ner-ontonotes_precision: 0.873, edges-ner-ontonotes_recall: 0.363, edges-ner-ontonotes_f1: 0.513
09/16 02:15:00 PM: Done!
09/16 02:15:00 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
